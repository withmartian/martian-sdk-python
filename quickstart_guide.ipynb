{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Martian SDK Quickstart Guide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T15:50:46.475967Z",
     "start_time": "2025-05-23T15:50:45.885343Z"
    }
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import openai\n",
    "from openai.types.chat import (\n",
    "    chat_completion,\n",
    "    chat_completion_message,\n",
    ")\n",
    "\n",
    "from martian_apart_hack_sdk import judge_specs, martian_client, utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Credentials\n",
    "You must have a .env file with the following values set:\n",
    "\n",
    "1. `MARTIAN_API_URL` - withmartian.com/api\n",
    "1. `MARTIAN_ORG_ID` - your Martain organization ID\n",
    "1. `MARTIAN_API_KEY` - your personal API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T15:51:18.520387Z",
     "start_time": "2025-05-23T15:51:18.512964Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the config and make a client.\n",
    "config = utils.load_config()\n",
    "client = martian_client.MartianClient(\n",
    "    api_url=config.api_url,\n",
    "    api_key=config.api_key,\n",
    "    org_id=config.org_id,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Martian Gateway\n",
    "\n",
    "You can use Martian as a gateway to access a number of different LLM providers.\n",
    "To do so, you start by making an OpenAI client with the base_url set to the Martian API URL + \"/openai/v2\".\n",
    "Then you can use the client as you would when working with OpenAI.\n",
    "\n",
    "The list of available models are:\n",
    "\n",
    "- gpt-4.5-preview\n",
    "- gpt-4.1\n",
    "- gpt-4.1-mini\n",
    "- gpt-4.1-nano\n",
    "- gpt-4o\n",
    "- gpt-4o-mini\n",
    "- o3-mini\n",
    "\n",
    "- claude-3-opus-latest\n",
    "- claude-3-5-haiku-latest\n",
    "- claude-3-5-sonnet-latest\n",
    "- claude-3-7-sonnet-latest\n",
    "\n",
    "- together/deepseek-ai/DeepSeek-R1\n",
    "- together/deepseek-ai/DeepSeek-V3\n",
    "- together/mistralai/Mistral-Small-24B-Instruct-2501\n",
    "- together/nvidia/Llama-3.1-Nemotron-70B-Instruct-HF\n",
    "- together/meta-llama/Llama-3.3-70B-Instruct-Turbo\n",
    "- together/meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo\n",
    "- together/Qwen/Qwen2.5-72B-Instruct-Turbo\n",
    "- together/Qwen/Qwen2.5-Coder-32B-Instruct\n",
    "- together/google/gemma-2-27b-it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-4o-mini says: The capital of France is **Paris**. ðŸ‡«ðŸ‡· \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create the client.\n",
    "openai_client = openai.OpenAI(\n",
    "    api_key=config.api_key,\n",
    "    base_url=config.api_url + \"/openai/v2\"\n",
    ")\n",
    "\n",
    "# Create a request.\n",
    "gpt_nano_chat_completion_response = openai_client.chat.completions.create(\n",
    "    model=\"gpt-4.1-nano\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"What is the capital of France?\"}],\n",
    ")\n",
    "claude_3_haiku_chat_completion_response = openai_client.chat.completions.create(\n",
    "    model=\"claude-3-5-haiku-latest\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"What is the capital of France?\"}],\n",
    ")\n",
    "gemma_2_chat_completion_response = openai_client.chat.completions.create(\n",
    "    model=\"gemma-2-27b-it\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"What is the capital of France?\"}],\n",
    ")\n",
    "\n",
    "# Get the response.\n",
    "print(\"gpt-4.1-nano says:\", gpt_nano_chat_completion_response.llm_response[\"choices\"][0][\"message\"][\"content\"])  # type: ignore\n",
    "print(\"claude-3-5-haiku-latest says:\", claude_3_haiku_chat_completion_response.llm_response[\"choices\"][0][\"message\"][\"content\"])  # type: ignore\n",
    "print(\"gemma-2-27b-it says:\", gemma_2_chat_completion_response.llm_response[\"choices\"][0][\"message\"][\"content\"])  # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Judging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T15:51:39.039815Z",
     "start_time": "2025-05-23T15:51:39.032192Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a JudgeSpec\n",
    "\n",
    "rubric = \"\"\"\n",
    "You are tasked with evaluating whether a restaurant recommendation is good.\n",
    "The scoring is as follows:\n",
    "- 1: If the recommendation doesn't meet any of the criteria.\n",
    "- 2: If the recommendation meets only some small part of the criteria.\n",
    "- 3: If the recommendation is reasonable, but not perfect.\n",
    "- 4: If the recommendation is almost perfect.\n",
    "- 5: If the recommendation is perfect.\n",
    "\"\"\".strip()\n",
    "\n",
    "rubric_judge_spec = judge_specs.RubricJudgeSpec(\n",
    "    model_type=\"rubric_judge\",\n",
    "    rubric=rubric,\n",
    "    # TODO: Clearly communicate which models are available.\n",
    "    model=\"openai/openai/gpt-4o\",\n",
    "    min_score=1,\n",
    "    max_score=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T15:52:31.344885Z",
     "start_time": "2025-05-23T15:52:29.135526Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: What is a good Chinese restaurant in downtown San Francisco?\n",
      "Assistant: I couldn't find a good Mexican restaurant near you.\n",
      "Evaluation result: JudgeEvaluation(score=1, reason=\"\\nThe assistant's response does not address the user's specific request for a Chinese restaurant in downtown San Francisco. Instead, it incorrectly discusses Mexican restaurants, which is unrelated to the user's question. According to the rubric, the recommendation does not meet any of the criteria required, as it completely fails to provide a relevant response. Thus, it deserves the lowest score possible.\\n\", cost=0.0015225)\n"
     ]
    }
   ],
   "source": [
    "# Run the judge spec.\n",
    "# TODO: Go through advanced judge building.\n",
    "\n",
    "chat_request_text = \"What is a good Chinese restaurant in downtown San Francisco?\"\n",
    "chat_response_text = \"I couldn't find a good Mexican restaurant near you.\"\n",
    "\n",
    "completion_request = {\n",
    "    \"model\": \"openai/openai/gpt-4o-mini\",\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": chat_request_text}],\n",
    "}\n",
    "chat_completion_response = chat_completion.ChatCompletion(\n",
    "    id=\"123\",\n",
    "    choices=[\n",
    "        chat_completion.Choice(\n",
    "            finish_reason=\"stop\",\n",
    "            index=0,\n",
    "            message=chat_completion_message.ChatCompletionMessage(\n",
    "                role=\"assistant\",\n",
    "                content=chat_response_text,\n",
    "            ),\n",
    "        )\n",
    "    ],\n",
    "    created=0,\n",
    "    model=\"gpt-4o\",\n",
    "    object=\"chat.completion\",\n",
    "    service_tier=None,\n",
    ")\n",
    "\n",
    "evaluation_result = client.judges.evaluate_judge_spec(\n",
    "    rubric_judge_spec.to_dict(),\n",
    "    completion_request=completion_request,\n",
    "    completion_response=chat_completion_response,\n",
    ")\n",
    "\n",
    "print(f\"User: {chat_request_text}\")\n",
    "print(f\"Assistant: {chat_response_text}\")\n",
    "print(f\"Evaluation result: {evaluation_result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T15:52:53.335609Z",
     "start_time": "2025-05-23T15:52:53.284009Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created a judge: Judge(id='restaurant-recommendation-reviewer', version=1, description='A judge that rates how good restaurant recommendations are.', createTime='2025-05-23T15:52:53.326120Z', name='organizations/68275a4af88f39d6440c1050/judges/restaurant-recommendation-reviewer', judgeSpec={'extract_judgement': {'extraction_fields': [{'extraction_pattern': '<rationale>(.*?)</rationale>', 'field_type': 'STRING', 'match_index': -1, 'name': 'rationale', 'required': True}, {'extraction_pattern': '<score>(.*?)</score>', 'field_type': 'FLOAT', 'match_index': -1, 'name': 'score', 'required': True}], 'model_type': 'regex_extractor'}, 'extract_variables': {'extraction_fields': [{'extraction_pattern': '', 'field_type': 'STRING', 'match_index': 0, 'name': 'content', 'required': True}], 'model_type': 'default_extractor'}, 'max_score': 5, 'min_score': 1, 'model': 'openai/openai/gpt-4o', 'model_type': 'rubric_judge', 'postscript': \"Here's the conversation you are judging:\\n<content>\\n${content}\\n</content>\\n\\nPlease evaluate the assistant's response in the conversation above according to the rubric.\\nThink step-by-step to produce a score, and please provide a rationale for your score.\\nYour score should be between ${min_score} and ${max_score}.\\n\\nYour response MUST include:\\n1. A <rationale>...</rationale> tag containing your explanation\\n2. A <score>...</score> tag containing your numerical score\\n\", 'prescript': 'You are a helpful assistant that scores responses between ${min_score} and ${max_score} according to the following rubric:', 'rubric': \"You are tasked with evaluating whether a restaurant recommendation is good.\\nThe scoring is as follows:\\n- 1: If the recommendation doesn't meet any of the criteria.\\n- 2: If the recommendation meets only some small part of the criteria.\\n- 3: If the recommendation is reasonable, but not perfect.\\n- 4: If the recommendation is almost perfect.\\n- 5: If the recommendation is perfect.\"})\n"
     ]
    }
   ],
   "source": [
    "# Once you are happy with the judge, you can save it.\n",
    "\n",
    "judge_id = \"restaurant-recommendation-reviewer\"\n",
    "\n",
    "judge = client.judges.create_judge(\n",
    "    judge_id=judge_id,\n",
    "    judge_spec=rubric_judge_spec,\n",
    "    description=\"A judge that rates how good restaurant recommendations are.\"\n",
    ")\n",
    "\n",
    "print(f\"Created a judge: {judge}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T15:53:00.160848Z",
     "start_time": "2025-05-23T15:52:58.407172Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'judgement': {'score': 1, 'reason': \"\\nThe assistant's response is entirely irrelevant to the user's question. The user asked for a recommendation of a Chinese restaurant in downtown San Francisco, but the assistant responded with information about a Mexican restaurant, which is not what was requested. This means that the response does not meet any of the criteria set out for evaluating a good restaurant recommendation. Therefore, based on the rubric, the assistant's response merits the lowest possible score because it fails to provide any helpful information regarding the user's request.\\n\", 'cost': 0.0017625}}\n",
      "Judge response: JudgeEvaluation(score=1, reason=\"\\nThe assistant's response is entirely irrelevant to the user's question. The user asked for a recommendation of a Chinese restaurant in downtown San Francisco, but the assistant responded with information about a Mexican restaurant, which is not what was requested. This means that the response does not meet any of the criteria set out for evaluating a good restaurant recommendation. Therefore, based on the rubric, the assistant's response merits the lowest possible score because it fails to provide any helpful information regarding the user's request.\\n\", cost=0.0017625)\n"
     ]
    }
   ],
   "source": [
    "# You can then call the judge:\n",
    "\n",
    "evaluation_result = client.judges.evaluate_judge(\n",
    "    judge,\n",
    "    completion_request=completion_request,\n",
    "    completion_response=chat_completion_response,\n",
    ")\n",
    "\n",
    "print(f\"Judge response: {evaluation_result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T15:53:12.743103Z",
     "start_time": "2025-05-23T15:53:12.682051Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Judges:\n",
      "\t- Judge(id='restaurant-recommendation-reviewer', version=1, description='A judge that rates how good restaurant recommendations are.', createTime='2025-05-23T15:52:53.326120Z', name='organizations/68275a4af88f39d6440c1050/judges/restaurant-recommendation-reviewer', judgeSpec=None) \t- Judge(id='my-rubric-judge', version=11, description='', createTime='2025-05-23T15:40:09.091441Z', name='organizations/68275a4af88f39d6440c1050/judges/my-rubric-judge', judgeSpec=None) \t- Judge(id='rubric-judge', version=1, description='', createTime='2025-05-23T15:22:05.194690Z', name='organizations/68275a4af88f39d6440c1050/judges/rubric-judge', judgeSpec=None) \t- Judge(id='new-quality-rubric-judge', version=2, description='A judge that evaluates response quality based on accuracy, completeness, clarity, and helpfulness', createTime='2025-05-22T14:01:07.021971Z', name='organizations/68275a4af88f39d6440c1050/judges/new-quality-rubric-judge', judgeSpec=None) \t- Judge(id='rubric-judge-test-id', version=4, description='', createTime='2025-05-22T13:36:56.949726Z', name='organizations/68275a4af88f39d6440c1050/judges/rubric-judge-test-id', judgeSpec=None) \t- Judge(id='rubric-judge-id-new', version=1, description='', createTime='2025-05-22T10:36:02.139936Z', name='organizations/68275a4af88f39d6440c1050/judges/rubric-judge-id-new', judgeSpec=None) \t- Judge(id='rubric-judge-id', version=1, description='', createTime='2025-05-22T10:33:05.950705Z', name='organizations/68275a4af88f39d6440c1050/judges/rubric-judge-id', judgeSpec=None) \t- Judge(id='my_cool_judge_id', version=1, description='This is a new judge description.', createTime='2025-05-21T20:03:01.046015Z', name='organizations/68275a4af88f39d6440c1050/judges/my_cool_judge_id', judgeSpec=None) \t- Judge(id='my_cool_judge', version=1, description='This is a new judge description.', createTime='2025-05-21T19:47:20.466892Z', name='organizations/68275a4af88f39d6440c1050/judges/my_cool_judge', judgeSpec=None) \t- Judge(id='my_super_judge3', version=1, description='', createTime='2025-05-21T19:46:18.715056Z', name='organizations/68275a4af88f39d6440c1050/judges/my_super_judge3', judgeSpec=None) \t- Judge(id='my_super_judge2', version=1, description='', createTime='2025-05-21T19:44:13.600781Z', name='organizations/68275a4af88f39d6440c1050/judges/my_super_judge2', judgeSpec=None) \t- Judge(id='my_super_judge', version=1, description='', createTime='2025-05-21T19:38:10.138100Z', name='organizations/68275a4af88f39d6440c1050/judges/my_super_judge', judgeSpec=None) \t- Judge(id='quality-rubric-judge', version=2, description='A judge that evaluates response quality based on accuracy, completeness, clarity, and helpfulness', createTime='2025-05-21T00:29:17.998842Z', name='organizations/68275a4af88f39d6440c1050/judges/quality-rubric-judge', judgeSpec=None)\n",
      "\n",
      "Retrieved judge: Judge(id='restaurant-recommendation-reviewer', version=1, description='A judge that rates how good restaurant recommendations are.', createTime='2025-05-23T15:52:53.326120Z', name='organizations/68275a4af88f39d6440c1050/judges/restaurant-recommendation-reviewer', judgeSpec={'extract_judgement': {'extraction_fields': [{'extraction_pattern': '<rationale>(.*?)</rationale>', 'field_type': 'STRING', 'match_index': -1, 'name': 'rationale', 'required': True}, {'extraction_pattern': '<score>(.*?)</score>', 'field_type': 'FLOAT', 'match_index': -1, 'name': 'score', 'required': True}], 'model_type': 'regex_extractor'}, 'extract_variables': {'extraction_fields': [{'extraction_pattern': '', 'field_type': 'STRING', 'match_index': 0, 'name': 'content', 'required': True}], 'model_type': 'default_extractor'}, 'max_score': 5, 'min_score': 1, 'model': 'openai/openai/gpt-4o', 'model_type': 'rubric_judge', 'postscript': \"Here's the conversation you are judging:\\n<content>\\n${content}\\n</content>\\n\\nPlease evaluate the assistant's response in the conversation above according to the rubric.\\nThink step-by-step to produce a score, and please provide a rationale for your score.\\nYour score should be between ${min_score} and ${max_score}.\\n\\nYour response MUST include:\\n1. A <rationale>...</rationale> tag containing your explanation\\n2. A <score>...</score> tag containing your numerical score\\n\", 'prescript': 'You are a helpful assistant that scores responses between ${min_score} and ${max_score} according to the following rubric:', 'rubric': \"You are tasked with evaluating whether a restaurant recommendation is good.\\nThe scoring is as follows:\\n- 1: If the recommendation doesn't meet any of the criteria.\\n- 2: If the recommendation meets only some small part of the criteria.\\n- 3: If the recommendation is reasonable, but not perfect.\\n- 4: If the recommendation is almost perfect.\\n- 5: If the recommendation is perfect.\"})\n",
      "\n",
      "New judge spec: Judge(id='restaurant-recommendation-reviewer', version=2, description='A judge that rates how good restaurant recommendations are.', createTime='2025-05-23T15:53:12.734947Z', name='organizations/68275a4af88f39d6440c1050/judges/restaurant-recommendation-reviewer', judgeSpec={'extract_judgement': {'extraction_fields': [{'extraction_pattern': '<rationale>(.*?)</rationale>', 'field_type': 'STRING', 'match_index': -1, 'name': 'rationale', 'required': True}, {'extraction_pattern': '<score>(.*?)</score>', 'field_type': 'FLOAT', 'match_index': -1, 'name': 'score', 'required': True}], 'model_type': 'regex_extractor'}, 'extract_variables': {'extraction_fields': [{'extraction_pattern': '', 'field_type': 'STRING', 'match_index': 0, 'name': 'content', 'required': True}], 'model_type': 'default_extractor'}, 'max_score': 5, 'min_score': 1, 'model': 'openai/openai/gpt-4o', 'model_type': 'rubric_judge', 'postscript': \"Here's the conversation you are judging:\\n<content>\\n${content}\\n</content>\\n\\nPlease evaluate the assistant's response in the conversation above according to the rubric.\\nThink step-by-step to produce a score, and please provide a rationale for your score.\\nYour score should be between ${min_score} and ${max_score}.\\n\\nYour response MUST include:\\n1. A <rationale>...</rationale> tag containing your explanation\\n2. A <score>...</score> tag containing your numerical score\\n\", 'prescript': 'You are a helpful assistant that scores responses between ${min_score} and ${max_score} according to the following rubric:', 'rubric': \"You are tasked with evaluating whether a restaurant recommendation is good.\\nThe scoring is as follows:\\n- 1: If the recommendation doesn't meet any of the criteria.\\n- 2: If the recommendation meets only some small part of the criteria.\\n- 3: If the recommendation is reasonable, but not perfect.\\n- 4: If the recommendation is almost perfect.\\n- 5: If the recommendation is perfect.\"})\n"
     ]
    }
   ],
   "source": [
    "# Once you have created some judges, you may want to list them all:\n",
    "\n",
    "all_judges = client.judges.list()\n",
    "print(\"Judges:\")\n",
    "print(*[f\"\\t- {j}\" for j in all_judges])\n",
    "\n",
    "# Or get a specific judge:\n",
    "\n",
    "retrieved_judge = client.judges.get(\n",
    "    judge_id=\"restaurant-recommendation-reviewer\",\n",
    "    version=1,\n",
    ")\n",
    "print(f\"\\nRetrieved judge: {retrieved_judge}\")\n",
    "\n",
    "# Or update the judge, creating a new version:\n",
    "\n",
    "\n",
    "new_rubric = \"\"\"\n",
    "You are tasked with evaluating whether a restaurant recommendation is good.\n",
    "The scoring is as follows:\n",
    "- 1: If the recommendation doesn't meet any of the criteria.\n",
    "- 2: If the recommendation meets only some small part of the criteria.\n",
    "- 3: If the recommendation is reasonable, but not perfect.\n",
    "- 4: If the recommendation is almost perfect.\n",
    "- 5: If the recommendation is perfect.\n",
    "\"\"\".strip()\n",
    "\n",
    "new_rubric_judge_spec = judge_specs.RubricJudgeSpec(\n",
    "    model_type=\"rubric_judge\",\n",
    "    rubric=rubric,\n",
    "    # TODO: Clearly communicate which models are available.\n",
    "    model=\"openai/openai/gpt-4o\",\n",
    "    min_score=1,\n",
    "    max_score=5,\n",
    ")\n",
    "\n",
    "new_judge_spec = client.judges.update_judge(\n",
    "    judge_id=\"restaurant-recommendation-reviewer\",\n",
    "    judge_spec=new_rubric_judge_spec,\n",
    ")\n",
    "\n",
    "print(f\"\\nNew judge spec: {new_judge_spec}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Routing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
