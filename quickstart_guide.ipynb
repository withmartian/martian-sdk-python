{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Martian SDK Quickstart Guide"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T17:36:06.997135Z",
     "start_time": "2025-05-23T17:36:06.991158Z"
    }
   },
   "source": [
    "# Imports\n",
    "import openai\n",
    "from openai.types.chat import (\n",
    "    chat_completion,\n",
    "    chat_completion_message,\n",
    ")\n",
    "\n",
    "from martian_apart_hack_sdk import judge_specs, martian_client, utils\n",
    "from martian_apart_hack_sdk.models import RouterConstraints"
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Credentials\n",
    "You must have a .env file with the following values set:\n",
    "\n",
    "1. `MARTIAN_API_URL` - withmartian.com/api\n",
    "1. `MARTIAN_ORG_ID` - your Martain organization ID\n",
    "1. `MARTIAN_API_KEY` - your personal API key"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Load the config and make a client.\n",
    "config = utils.load_config()\n",
    "client = martian_client.MartianClient(\n",
    "    api_url=config.api_url,\n",
    "    api_key=config.api_key,\n",
    "    org_id=config.org_id,\n",
    ")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Judging"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "To create a basic rubric-based judge with a numeric scoring model, you just need to provide the rubric, the minimum and maximum scores, and the model you'd like to use as the judge.\n",
    "\n",
    "MARTIAN'S TIP: It's better to use discrete numbers—and, if possible, a binary scale—to minimize potential biases."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T17:24:29.693525Z",
     "start_time": "2025-05-23T17:24:29.686140Z"
    }
   },
   "source": [
    "# Create a JudgeSpec\n",
    "\n",
    "rubric = \"\"\"\n",
    "You are tasked with evaluating whether a restaurant recommendation is good.\n",
    "The scoring is as follows:\n",
    "- 1: If the recommendation doesn't meet any of the criteria.\n",
    "- 2: If the recommendation meets only some small part of the criteria.\n",
    "- 3: If the recommendation is reasonable, but not perfect.\n",
    "- 4: If the recommendation is almost perfect.\n",
    "- 5: If the recommendation is perfect.\n",
    "\"\"\".strip()\n",
    "\n",
    "rubric_judge_spec = judge_specs.RubricJudgeSpec(\n",
    "    model_type=\"rubric_judge\",\n",
    "    rubric=rubric,\n",
    "    model=\"openai/openai/gpt-4o\",\n",
    "    min_score=1,\n",
    "    max_score=5,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T17:24:37.491484Z",
     "start_time": "2025-05-23T17:24:35.157915Z"
    }
   },
   "source": [
    "# Run the judge spec.\n",
    "\n",
    "chat_request_text = \"What is a good Chinese restaurant in downtown San Francisco?\"\n",
    "chat_response_text = \"I couldn't find a good Mexican restaurant near you.\"\n",
    "\n",
    "completion_request = {\n",
    "    \"model\": \"openai/openai/gpt-4o-mini\",\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": chat_request_text}],\n",
    "}\n",
    "chat_completion_response = chat_completion.ChatCompletion(\n",
    "    id=\"123\",\n",
    "    choices=[\n",
    "        chat_completion.Choice(\n",
    "            finish_reason=\"stop\",\n",
    "            index=0,\n",
    "            message=chat_completion_message.ChatCompletionMessage(\n",
    "                role=\"assistant\",\n",
    "                content=chat_response_text,\n",
    "            ),\n",
    "        )\n",
    "    ],\n",
    "    created=0,\n",
    "    model=\"gpt-4o\",\n",
    "    object=\"chat.completion\",\n",
    "    service_tier=None,\n",
    ")\n",
    "\n",
    "evaluation_result = client.judges.evaluate_judge_spec(\n",
    "    rubric_judge_spec.to_dict(),\n",
    "    completion_request=completion_request,\n",
    "    completion_response=chat_completion_response,\n",
    ")\n",
    "\n",
    "print(f\"User: {chat_request_text}\")\n",
    "print(f\"Assistant: {chat_response_text}\")\n",
    "print(f\"Evaluation result: {evaluation_result}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: What is a good Chinese restaurant in downtown San Francisco?\n",
      "Assistant: I couldn't find a good Mexican restaurant near you.\n",
      "Evaluation result: JudgeEvaluation(score=1, reason=\"\\nThe assistant's response does not meet the user's request at all. The user asked for a recommendation for a Chinese restaurant in downtown San Francisco, but the assistant responded with information about a Mexican restaurant, which is irrelevant and entirely unrelated to the user's query. The response fails to address any part of the user's request for a Chinese restaurant recommendation. Thus, the recommendation does not meet any of the criteria outlined in the rubric.\\n\", cost=0.0016425)\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Once you're satisfied with the judge, you can save it."
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T15:52:53.335609Z",
     "start_time": "2025-05-23T15:52:53.284009Z"
    }
   },
   "source": [
    "judge_id = \"restaurant-recommendation-reviewer\"\n",
    "\n",
    "judge = client.judges.create_judge(\n",
    "    judge_id=judge_id,\n",
    "    judge_spec=rubric_judge_spec,\n",
    "    description=\"A judge that rates how good restaurant recommendations are.\"\n",
    ")\n",
    "\n",
    "print(f\"Created a judge: {judge}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created a judge: Judge(id='restaurant-recommendation-reviewer', version=1, description='A judge that rates how good restaurant recommendations are.', createTime='2025-05-23T15:52:53.326120Z', name='organizations/68275a4af88f39d6440c1050/judges/restaurant-recommendation-reviewer', judgeSpec={'extract_judgement': {'extraction_fields': [{'extraction_pattern': '<rationale>(.*?)</rationale>', 'field_type': 'STRING', 'match_index': -1, 'name': 'rationale', 'required': True}, {'extraction_pattern': '<score>(.*?)</score>', 'field_type': 'FLOAT', 'match_index': -1, 'name': 'score', 'required': True}], 'model_type': 'regex_extractor'}, 'extract_variables': {'extraction_fields': [{'extraction_pattern': '', 'field_type': 'STRING', 'match_index': 0, 'name': 'content', 'required': True}], 'model_type': 'default_extractor'}, 'max_score': 5, 'min_score': 1, 'model': 'openai/openai/gpt-4o', 'model_type': 'rubric_judge', 'postscript': \"Here's the conversation you are judging:\\n<content>\\n${content}\\n</content>\\n\\nPlease evaluate the assistant's response in the conversation above according to the rubric.\\nThink step-by-step to produce a score, and please provide a rationale for your score.\\nYour score should be between ${min_score} and ${max_score}.\\n\\nYour response MUST include:\\n1. A <rationale>...</rationale> tag containing your explanation\\n2. A <score>...</score> tag containing your numerical score\\n\", 'prescript': 'You are a helpful assistant that scores responses between ${min_score} and ${max_score} according to the following rubric:', 'rubric': \"You are tasked with evaluating whether a restaurant recommendation is good.\\nThe scoring is as follows:\\n- 1: If the recommendation doesn't meet any of the criteria.\\n- 2: If the recommendation meets only some small part of the criteria.\\n- 3: If the recommendation is reasonable, but not perfect.\\n- 4: If the recommendation is almost perfect.\\n- 5: If the recommendation is perfect.\"})\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "You can now also evaluate the judge by its ID."
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T15:53:00.160848Z",
     "start_time": "2025-05-23T15:52:58.407172Z"
    }
   },
   "source": [
    "evaluation_result = client.judges.evaluate_judge(\n",
    "    judge,\n",
    "    completion_request=completion_request,\n",
    "    completion_response=chat_completion_response,\n",
    ")\n",
    "\n",
    "print(f\"Judge response: {evaluation_result}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'judgement': {'score': 1, 'reason': \"\\nThe assistant's response is entirely irrelevant to the user's question. The user asked for a recommendation of a Chinese restaurant in downtown San Francisco, but the assistant responded with information about a Mexican restaurant, which is not what was requested. This means that the response does not meet any of the criteria set out for evaluating a good restaurant recommendation. Therefore, based on the rubric, the assistant's response merits the lowest possible score because it fails to provide any helpful information regarding the user's request.\\n\", 'cost': 0.0017625}}\n",
      "Judge response: JudgeEvaluation(score=1, reason=\"\\nThe assistant's response is entirely irrelevant to the user's question. The user asked for a recommendation of a Chinese restaurant in downtown San Francisco, but the assistant responded with information about a Mexican restaurant, which is not what was requested. This means that the response does not meet any of the criteria set out for evaluating a good restaurant recommendation. Therefore, based on the rubric, the assistant's response merits the lowest possible score because it fails to provide any helpful information regarding the user's request.\\n\", cost=0.0017625)\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Once you have created some judges, you may want to list them all"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "all_judges = client.judges.list()\n",
    "print(\"Judges:\")\n",
    "print(*[f\"\\t- {j}\" for j in all_judges])"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "If you already know the ID, you can retrieve the judge."
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Or get a specific judge:\n",
    "retrieved_judge = client.judges.get(\n",
    "    judge_id=\"restaurant-recommendation-reviewer\",\n",
    "    version=1,\n",
    ")\n",
    "print(f\"\\nRetrieved judge: {retrieved_judge}\")\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Or you can update the judge to create a new version.\n",
    "\n",
    "MARTIAN TIP: Judges are immutable, so there's no risk of breaking anything when you update. For example, if your current production setup is using version 2 and you update the judge, it will simply create version 3 without affecting your existing production environment."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Judges:\n",
      "\t- Judge(id='restaurant-recommendation-reviewer', version=2, description='A judge that rates how good restaurant recommendations are.', createTime='2025-05-23T15:53:12.734947Z', name='organizations/68275a4af88f39d6440c1050/judges/restaurant-recommendation-reviewer', judgeSpec=None) \t- Judge(id='my-rubric-judge', version=11, description='', createTime='2025-05-23T15:40:09.091441Z', name='organizations/68275a4af88f39d6440c1050/judges/my-rubric-judge', judgeSpec=None) \t- Judge(id='rubric-judge', version=1, description='', createTime='2025-05-23T15:22:05.194690Z', name='organizations/68275a4af88f39d6440c1050/judges/rubric-judge', judgeSpec=None) \t- Judge(id='new-quality-rubric-judge', version=2, description='A judge that evaluates response quality based on accuracy, completeness, clarity, and helpfulness', createTime='2025-05-22T14:01:07.021971Z', name='organizations/68275a4af88f39d6440c1050/judges/new-quality-rubric-judge', judgeSpec=None) \t- Judge(id='rubric-judge-test-id', version=4, description='', createTime='2025-05-22T13:36:56.949726Z', name='organizations/68275a4af88f39d6440c1050/judges/rubric-judge-test-id', judgeSpec=None) \t- Judge(id='rubric-judge-id-new', version=1, description='', createTime='2025-05-22T10:36:02.139936Z', name='organizations/68275a4af88f39d6440c1050/judges/rubric-judge-id-new', judgeSpec=None) \t- Judge(id='rubric-judge-id', version=1, description='', createTime='2025-05-22T10:33:05.950705Z', name='organizations/68275a4af88f39d6440c1050/judges/rubric-judge-id', judgeSpec=None) \t- Judge(id='my_cool_judge_id', version=1, description='This is a new judge description.', createTime='2025-05-21T20:03:01.046015Z', name='organizations/68275a4af88f39d6440c1050/judges/my_cool_judge_id', judgeSpec=None) \t- Judge(id='my_cool_judge', version=1, description='This is a new judge description.', createTime='2025-05-21T19:47:20.466892Z', name='organizations/68275a4af88f39d6440c1050/judges/my_cool_judge', judgeSpec=None) \t- Judge(id='my_super_judge3', version=1, description='', createTime='2025-05-21T19:46:18.715056Z', name='organizations/68275a4af88f39d6440c1050/judges/my_super_judge3', judgeSpec=None) \t- Judge(id='my_super_judge2', version=1, description='', createTime='2025-05-21T19:44:13.600781Z', name='organizations/68275a4af88f39d6440c1050/judges/my_super_judge2', judgeSpec=None) \t- Judge(id='my_super_judge', version=1, description='', createTime='2025-05-21T19:38:10.138100Z', name='organizations/68275a4af88f39d6440c1050/judges/my_super_judge', judgeSpec=None) \t- Judge(id='quality-rubric-judge', version=2, description='A judge that evaluates response quality based on accuracy, completeness, clarity, and helpfulness', createTime='2025-05-21T00:29:17.998842Z', name='organizations/68275a4af88f39d6440c1050/judges/quality-rubric-judge', judgeSpec=None)\n",
      "\n",
      "Retrieved judge: Judge(id='restaurant-recommendation-reviewer', version=1, description='A judge that rates how good restaurant recommendations are.', createTime='2025-05-23T15:52:53.326120Z', name='organizations/68275a4af88f39d6440c1050/judges/restaurant-recommendation-reviewer', judgeSpec={'extract_judgement': {'extraction_fields': [{'extraction_pattern': '<rationale>(.*?)</rationale>', 'field_type': 'STRING', 'match_index': -1, 'name': 'rationale', 'required': True}, {'extraction_pattern': '<score>(.*?)</score>', 'field_type': 'FLOAT', 'match_index': -1, 'name': 'score', 'required': True}], 'model_type': 'regex_extractor'}, 'extract_variables': {'extraction_fields': [{'extraction_pattern': '', 'field_type': 'STRING', 'match_index': 0, 'name': 'content', 'required': True}], 'model_type': 'default_extractor'}, 'max_score': 5, 'min_score': 1, 'model': 'openai/openai/gpt-4o', 'model_type': 'rubric_judge', 'postscript': \"Here's the conversation you are judging:\\n<content>\\n${content}\\n</content>\\n\\nPlease evaluate the assistant's response in the conversation above according to the rubric.\\nThink step-by-step to produce a score, and please provide a rationale for your score.\\nYour score should be between ${min_score} and ${max_score}.\\n\\nYour response MUST include:\\n1. A <rationale>...</rationale> tag containing your explanation\\n2. A <score>...</score> tag containing your numerical score\\n\", 'prescript': 'You are a helpful assistant that scores responses between ${min_score} and ${max_score} according to the following rubric:', 'rubric': \"You are tasked with evaluating whether a restaurant recommendation is good.\\nThe scoring is as follows:\\n- 1: If the recommendation doesn't meet any of the criteria.\\n- 2: If the recommendation meets only some small part of the criteria.\\n- 3: If the recommendation is reasonable, but not perfect.\\n- 4: If the recommendation is almost perfect.\\n- 5: If the recommendation is perfect.\"})\n",
      "\n",
      "New judge spec: Judge(id='restaurant-recommendation-reviewer', version=3, description='A judge that rates how good restaurant recommendations are.', createTime='2025-05-23T17:43:27.604496Z', name='organizations/68275a4af88f39d6440c1050/judges/restaurant-recommendation-reviewer', judgeSpec={'extract_judgement': {'extraction_fields': [{'extraction_pattern': '<rationale>(.*?)</rationale>', 'field_type': 'STRING', 'match_index': -1, 'name': 'rationale', 'required': True}, {'extraction_pattern': '<score>(.*?)</score>', 'field_type': 'FLOAT', 'match_index': -1, 'name': 'score', 'required': True}], 'model_type': 'regex_extractor'}, 'extract_variables': {'extraction_fields': [{'extraction_pattern': '', 'field_type': 'STRING', 'match_index': 0, 'name': 'content', 'required': True}], 'model_type': 'default_extractor'}, 'max_score': 5, 'min_score': 1, 'model': 'openai/openai/gpt-4o', 'model_type': 'rubric_judge', 'postscript': \"Here's the conversation you are judging:\\n<content>\\n${content}\\n</content>\\n\\nPlease evaluate the assistant's response in the conversation above according to the rubric.\\nThink step-by-step to produce a score, and please provide a rationale for your score.\\nYour score should be between ${min_score} and ${max_score}.\\n\\nYour response MUST include:\\n1. A <rationale>...</rationale> tag containing your explanation\\n2. A <score>...</score> tag containing your numerical score\\n\", 'prescript': 'You are a helpful assistant that scores responses between ${min_score} and ${max_score} according to the following rubric:', 'rubric': \"You are tasked with evaluating whether a restaurant recommendation is good.\\nThe scoring is as follows:\\n- 1: If the recommendation doesn't meet any of the criteria.\\n- 2: If the recommendation meets only some small part of the criteria.\\n- 3: If the recommendation is reasonable, but not perfect.\\n- 4: If the recommendation is almost perfect.\\n- 5: If the recommendation is perfect.\"})\n"
     ]
    }
   ],
   "execution_count": 32,
   "source": [
    "new_rubric = \"\"\"\n",
    "You are tasked with evaluating whether a restaurant recommendation is good.\n",
    "The scoring is as follows:\n",
    "- 1: If the recommendation doesn't meet any of the criteria.\n",
    "- 2: If the recommendation meets only some small part of the criteria.\n",
    "- 3: If the recommendation is reasonable, but not perfect.\n",
    "- 4: If the recommendation is almost perfect.\n",
    "- 5: If the recommendation is perfect.\n",
    "\"\"\".strip()\n",
    "\n",
    "new_rubric_judge_spec = judge_specs.RubricJudgeSpec(\n",
    "    model_type=\"rubric_judge\",\n",
    "    rubric=rubric,\n",
    "    # TODO: Clearly communicate which models are available.\n",
    "    model=\"openai/openai/gpt-4o\",\n",
    "    min_score=1,\n",
    "    max_score=5,\n",
    ")\n",
    "\n",
    "new_judge_spec = client.judges.update_judge(\n",
    "    judge_id=\"restaurant-recommendation-reviewer\",\n",
    "    judge_spec=new_rubric_judge_spec,\n",
    ")\n",
    "\n",
    "print(f\"\\nNew judge spec: {new_judge_spec}\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Example of a More Complex Judge\n",
    "We can start with a specification that includes not only the rubric but also a customized prescript (which is added to the judge prompt before the rubric) and postscript (which goes after the rubric). This setup is typically used to customize how your judge processes requests."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T18:02:29.385208Z",
     "start_time": "2025-05-23T18:02:29.376966Z"
    }
   },
   "cell_type": "code",
   "source": "json_spec = '{\\n  \"model_type\": \"rubric_judge\",\\n  \"rubric\": \"Is important question helps to advance to the target?\",\\n  \"model\": \"gpt-4o-mini\",\\n  \"min_score\": 1.0,\\n  \"max_score\": 4.0,\\n  \"prescript\": \"target of the conversation: ${target}.\\\\nConversation: ${conversation}.important question: ${important_question}.\\\\n\\\\n\",\\n  \"postscript\": \"Please evaluate conversation according to the rubric.\\\\nThink step-by-step to produce a score, and please provide a rationale for your score.\\\\nYour score should be between ${min_score} and ${max_score}.\\\\n\\\\nYour response MUST include:\\\\n1. A <rationale>...</rationale> tag containing your explanation\\\\n2. A <score>...</score> tag containing your numerical score\\\\n\",\\n  \"extract_variables\": {\\n    \"model_type\": \"combined_extractor\",\\n    \"extraction_fields\": [\\n      {\\n        \"name\": \"target\",\\n        \"field_type\": \"STRING\",\\n        \"required\": true,\\n        \"extraction_pattern\": \"\\\\\"target\\\\\":\\\\\"([\\\\\\\\S\\\\\\\\s]*?)\\\\\"\",\\n        \"match_index\": 0\\n      },\\n      {\\n        \"name\": \"important_question\",\\n        \"field_type\": \"STRING\",\\n        \"required\": true,\\n        \"extraction_pattern\": \"\\\\\"important\\\\\", \\\\\"question\\\\\": \\\\\"([\\\\\\\\s\\\\\\\\S]*?)\\\\\"\",\\n        \"match_index\": -1\\n      },\\n      {\\n        \"name\": \"conversation\",\\n        \"field_type\": \"STRING\",\\n        \"required\": true,\\n        \"extraction_pattern\": null,\\n        \"match_index\": 0\\n      }\\n    ],\\n    \"extractors\": [\\n      {\\n        \"model_type\": \"regex_extractor\",\\n        \"extraction_fields\": [\\n          {\\n            \"name\": \"target\",\\n            \"field_type\": \"STRING\",\\n            \"required\": true,\\n            \"extraction_pattern\": \"\\\\\"target\\\\\":\\\\\"([\\\\\\\\S\\\\\\\\s]*?)\\\\\"\",\\n            \"match_index\": 0\\n          }\\n        ]\\n      },\\n      {\\n        \"model_type\": \"response_regex_extractor\",\\n        \"extraction_fields\": [\\n          {\\n            \"name\": \"important_question\",\\n            \"field_type\": \"STRING\",\\n            \"required\": true,\\n            \"extraction_pattern\": \"\\\\\"important\\\\\", \\\\\"question\\\\\": \\\\\"([\\\\\\\\s\\\\\\\\S]*?)\\\\\"\",\\n            \"match_index\": -1\\n          }\\n        ]\\n      },\\n      {\\n        \"model_type\": \"conversation_extractor\",\\n        \"extraction_fields\": [\\n          {\\n            \"name\": \"conversation\",\\n            \"field_type\": \"STRING\",\\n            \"required\": true,\\n            \"extraction_pattern\": null,\\n            \"match_index\": 0\\n          }\\n        ]\\n      }\\n    ]\\n  },\\n  \"extract_judgement\": {\\n    \"model_type\": \"regex_extractor\",\\n    \"extraction_fields\": [\\n      {\\n        \"name\": \"rationale\",\\n        \"field_type\": \"STRING\",\\n        \"required\": true,\\n        \"extraction_pattern\": \"<rationale>(.*?)</rationale>\",\\n        \"match_index\": -1\\n      },\\n      {\\n        \"name\": \"score\",\\n        \"field_type\": \"FLOAT\",\\n        \"required\": true,\\n        \"extraction_pattern\": \"<score>(.*?)</score>\",\\n        \"match_index\": -1\\n      }\\n    ]\\n  }\\n}'",
   "outputs": [],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T18:02:42.274366Z",
     "start_time": "2025-05-23T18:02:42.263174Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "json.loads(json_spec)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_type': 'rubric_judge',\n",
       " 'rubric': 'Is important question helps to advance to the target?',\n",
       " 'model': 'gpt-4o-mini',\n",
       " 'min_score': 1.0,\n",
       " 'max_score': 4.0,\n",
       " 'prescript': 'target of the conversation: ${target}.\\nConversation: ${conversation}.important question: ${important_question}.\\n\\n',\n",
       " 'postscript': 'Please evaluate conversation according to the rubric.\\nThink step-by-step to produce a score, and please provide a rationale for your score.\\nYour score should be between ${min_score} and ${max_score}.\\n\\nYour response MUST include:\\n1. A <rationale>...</rationale> tag containing your explanation\\n2. A <score>...</score> tag containing your numerical score\\n',\n",
       " 'extract_variables': {'model_type': 'combined_extractor',\n",
       "  'extraction_fields': [{'name': 'target',\n",
       "    'field_type': 'STRING',\n",
       "    'required': True,\n",
       "    'extraction_pattern': '\"target\":\"([\\\\S\\\\s]*?)\"',\n",
       "    'match_index': 0},\n",
       "   {'name': 'important_question',\n",
       "    'field_type': 'STRING',\n",
       "    'required': True,\n",
       "    'extraction_pattern': '\"important\", \"question\": \"([\\\\s\\\\S]*?)\"',\n",
       "    'match_index': -1},\n",
       "   {'name': 'conversation',\n",
       "    'field_type': 'STRING',\n",
       "    'required': True,\n",
       "    'extraction_pattern': None,\n",
       "    'match_index': 0}],\n",
       "  'extractors': [{'model_type': 'regex_extractor',\n",
       "    'extraction_fields': [{'name': 'target',\n",
       "      'field_type': 'STRING',\n",
       "      'required': True,\n",
       "      'extraction_pattern': '\"target\":\"([\\\\S\\\\s]*?)\"',\n",
       "      'match_index': 0}]},\n",
       "   {'model_type': 'response_regex_extractor',\n",
       "    'extraction_fields': [{'name': 'important_question',\n",
       "      'field_type': 'STRING',\n",
       "      'required': True,\n",
       "      'extraction_pattern': '\"important\", \"question\": \"([\\\\s\\\\S]*?)\"',\n",
       "      'match_index': -1}]},\n",
       "   {'model_type': 'conversation_extractor',\n",
       "    'extraction_fields': [{'name': 'conversation',\n",
       "      'field_type': 'STRING',\n",
       "      'required': True,\n",
       "      'extraction_pattern': None,\n",
       "      'match_index': 0}]}]},\n",
       " 'extract_judgement': {'model_type': 'regex_extractor',\n",
       "  'extraction_fields': [{'name': 'rationale',\n",
       "    'field_type': 'STRING',\n",
       "    'required': True,\n",
       "    'extraction_pattern': '<rationale>(.*?)</rationale>',\n",
       "    'match_index': -1},\n",
       "   {'name': 'score',\n",
       "    'field_type': 'FLOAT',\n",
       "    'required': True,\n",
       "    'extraction_pattern': '<score>(.*?)</score>',\n",
       "    'match_index': -1}]}}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T18:02:56.915456Z",
     "start_time": "2025-05-23T18:02:56.859871Z"
    }
   },
   "cell_type": "code",
   "source": [
    "judge_id = \"restaurant-recommendation-reviewer-310\"\n",
    "\n",
    "judge = client.judges.create_judge(\n",
    "    judge_id=judge_id,\n",
    "    judge_spec=json.loads(json_spec),\n",
    "    description=\"A judge that rates how helpful the question for the target is\"\n",
    ")\n",
    "\n",
    "print(f\"Created a judge: {judge}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created a judge: Judge(id='restaurant-recommendation-reviewer-310', version=1, description='A judge that rates how helpful the question for the target is', createTime='2025-05-23T18:02:56.905519Z', name='organizations/68275a4af88f39d6440c1050/judges/restaurant-recommendation-reviewer-310', judgeSpec={'extract_judgement': {'extraction_fields': [{'extraction_pattern': '<rationale>(.*?)</rationale>', 'field_type': 'STRING', 'match_index': -1, 'name': 'rationale', 'required': True}, {'extraction_pattern': '<score>(.*?)</score>', 'field_type': 'FLOAT', 'match_index': -1, 'name': 'score', 'required': True}], 'model_type': 'regex_extractor'}, 'extract_variables': {'extraction_fields': [{'extraction_pattern': '\"target\":\"([\\\\S\\\\s]*?)\"', 'field_type': 'STRING', 'match_index': 0, 'name': 'target', 'required': True}, {'extraction_pattern': '\"important\", \"question\": \"([\\\\s\\\\S]*?)\"', 'field_type': 'STRING', 'match_index': -1, 'name': 'important_question', 'required': True}, {'extraction_pattern': None, 'field_type': 'STRING', 'match_index': 0, 'name': 'conversation', 'required': True}], 'extractors': [{'extraction_fields': [{'extraction_pattern': '\"target\":\"([\\\\S\\\\s]*?)\"', 'field_type': 'STRING', 'match_index': 0, 'name': 'target', 'required': True}], 'model_type': 'regex_extractor'}, {'extraction_fields': [{'extraction_pattern': '\"important\", \"question\": \"([\\\\s\\\\S]*?)\"', 'field_type': 'STRING', 'match_index': -1, 'name': 'important_question', 'required': True}], 'model_type': 'response_regex_extractor'}, {'extraction_fields': [{'extraction_pattern': None, 'field_type': 'STRING', 'match_index': 0, 'name': 'conversation', 'required': True}], 'model_type': 'conversation_extractor'}], 'model_type': 'combined_extractor'}, 'max_score': 4, 'min_score': 1, 'model': 'gpt-4o-mini', 'model_type': 'rubric_judge', 'postscript': 'Please evaluate conversation according to the rubric.\\nThink step-by-step to produce a score, and please provide a rationale for your score.\\nYour score should be between ${min_score} and ${max_score}.\\n\\nYour response MUST include:\\n1. A <rationale>...</rationale> tag containing your explanation\\n2. A <score>...</score> tag containing your numerical score\\n', 'prescript': 'target of the conversation: ${target}.\\nConversation: ${conversation}.important question: ${important_question}.\\n\\n', 'rubric': 'Is important question helps to advance to the target?'})\n"
     ]
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Let's test it with an example request and response:"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T18:03:27.732761Z",
     "start_time": "2025-05-23T18:03:27.725282Z"
    }
   },
   "cell_type": "code",
   "source": [
    "completion_request = {\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": 'Help me to get to my target: \"target\":\"solve P=NP\"',\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Pls answer the question\",\n",
    "        },\n",
    "    ]\n",
    "}\n",
    "chat_completion_response = chat_completion.ChatCompletion(\n",
    "    id=\"123\",\n",
    "    choices=[\n",
    "        chat_completion.Choice(\n",
    "            finish_reason=\"stop\",\n",
    "            index=0,\n",
    "            message=chat_completion_message.ChatCompletionMessage(\n",
    "                role=\"assistant\",\n",
    "                content='{\"type\": \"important\", \"question\": \"Would like to use differential equations to solve P=NP?\"}',\n",
    "            ),\n",
    "        )\n",
    "    ],\n",
    "    created=0,\n",
    "    model=\"gpt-4o\",\n",
    "    object=\"chat.completion\",\n",
    "    service_tier=None,\n",
    ")\n"
   ],
   "outputs": [],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T18:03:41.031637Z",
     "start_time": "2025-05-23T18:03:38.742013Z"
    }
   },
   "cell_type": "code",
   "source": [
    "evaluation_result = client.judges.evaluate_judge(\n",
    "    judge,\n",
    "    completion_request=completion_request,\n",
    "    completion_response=chat_completion_response,\n",
    ")\n",
    "\n",
    "print(f\"Judge response: {evaluation_result}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Judge response: JudgeEvaluation(score=2, reason='In the conversation, the user expresses a desire to solve the P=NP problem, which is one of the most significant open questions in computer science. The important question posed—whether to use differential equations to approach this problem—does not clearly advance the discussion towards a solution. While interdisciplinary methods can be fruitful, differential equations are typically not associated with algorithms or complexity theory, which are central to the P=NP problem. Therefore, the question appears to diverge from the main goal rather than contribute meaningfully to solving it.', cost=9.465e-05)\n"
     ]
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Let's measure the IAA (Inter-Annotator Agreement) of our judge using the gold scores provided by domain experts."
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T18:05:24.135022Z",
     "start_time": "2025-05-23T18:05:03.505556Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import cohen_kappa_score\n",
    "# Define test examples\n",
    "def create_chat_completion(request_text: str, response_text: str) -> chat_completion.ChatCompletion:\n",
    "    \"\"\"Create a ChatCompletion object for testing.\"\"\"\n",
    "    return chat_completion.ChatCompletion(\n",
    "        id=\"test-completion\",\n",
    "        choices=[\n",
    "            chat_completion.Choice(\n",
    "                finish_reason=\"stop\",\n",
    "                index=0,\n",
    "                message=chat_completion_message.ChatCompletionMessage(\n",
    "                    role=\"assistant\",\n",
    "                    content=response_text,\n",
    "                ),\n",
    "            )\n",
    "        ],\n",
    "        created=0,\n",
    "        model=\"gpt-4o\",\n",
    "        object=\"chat.completion\",\n",
    "        service_tier=None,\n",
    "    )\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"request\": \"What's a good Chinese restaurant in San Francisco?\",\n",
    "        \"response\": \"I recommend China Live in Chinatown. It's known for its excellent dim sum, modern atmosphere, and authentic dishes. The prices are moderate, and they're located at 644 Broadway.\",\n",
    "        \"golden_score\": 5  # Perfect recommendation with details\n",
    "    },\n",
    "    {\n",
    "        \"request\": \"Where can I get good pizza in NYC?\",\n",
    "        \"response\": \"Sorry, I don't have access to restaurant information.\",\n",
    "        \"golden_score\": 1  # Completely unhelpful\n",
    "    },\n",
    "    {\n",
    "        \"request\": \"What's a good Mexican restaurant in Chicago?\",\n",
    "        \"response\": \"There's a Mexican restaurant downtown.\",\n",
    "        \"golden_score\": 2  # Very minimal information\n",
    "    },\n",
    "    {\n",
    "        \"request\": \"Recommend an Italian restaurant in Boston.\",\n",
    "        \"response\": \"Giacomo's in the North End is a popular Italian restaurant. They serve pasta and seafood.\",\n",
    "        \"golden_score\": 3  # Basic but reasonable recommendation\n",
    "    },\n",
    "    {\n",
    "        \"request\": \"What's a good sushi place in LA?\",\n",
    "        \"response\": \"Nobu Malibu is an excellent sushi restaurant with ocean views. They're known for their fresh fish and signature dishes, though they are on the expensive side.\",\n",
    "        \"golden_score\": 4  # Almost perfect, but could include location details\n",
    "    }\n",
    "]\n",
    "\n",
    "# Create judge spec\n",
    "rubric = \"\"\"\n",
    "You are tasked with evaluating whether a restaurant recommendation is good.\n",
    "The scoring is as follows:\n",
    "- 1: If the recommendation doesn't meet any of the criteria.\n",
    "- 2: If the recommendation meets only some small part of the criteria.\n",
    "- 3: If the recommendation is reasonable, but not perfect.\n",
    "- 4: If the recommendation is almost perfect.\n",
    "- 5: If the recommendation is perfect.\n",
    "\"\"\".strip()\n",
    "\n",
    "judge_spec = judge_specs.RubricJudgeSpec(\n",
    "    model_type=\"rubric_judge\",\n",
    "    rubric=rubric,\n",
    "    model=\"openai/openai/gpt-4o\",\n",
    "    min_score=1,\n",
    "    max_score=5,\n",
    ")\n",
    "\n",
    "# Evaluate examples\n",
    "judge_scores = []\n",
    "golden_scores = []\n",
    "\n",
    "print(\"\\nEvaluating examples...\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for i, example in enumerate(examples, 1):\n",
    "    # Create completion request and response\n",
    "    completion_request = {\n",
    "        \"model\": \"openai/openai/gpt-4o\",\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": example[\"request\"]}],\n",
    "    }\n",
    "    completion_response = create_chat_completion(example[\"request\"], example[\"response\"])\n",
    "\n",
    "    # Get judge's evaluation\n",
    "    evaluation = client.judges.evaluate_judge_spec(\n",
    "        judge_spec.to_dict(),\n",
    "        completion_request=completion_request,\n",
    "        completion_response=completion_response,\n",
    "    )\n",
    "\n",
    "    judge_scores.append(int(evaluation.score))\n",
    "    golden_scores.append(example[\"golden_score\"])\n",
    "\n",
    "    print(f\"\\nExample {i}:\")\n",
    "    print(f\"User: {example['request']}\")\n",
    "    print(f\"Assistant: {example['response']}\")\n",
    "    print(f\"Judge Score: {evaluation.score}\")\n",
    "    print(f\"Golden Score: {example['golden_score']}\")\n",
    "    #print(f\"Judge Rationale: {evaluation.rationale}\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "# Calculate Cohen's Kappa\n",
    "kappa = cohen_kappa_score(golden_scores, judge_scores)\n",
    "\n",
    "print(\"\\nResults Summary:\")\n",
    "print(f\"Number of examples evaluated: {len(examples)}\")\n",
    "print(f\"Cohen's Kappa Score: {kappa:.3f}\")\n",
    "print(\"\\nInterpretation of Kappa Score:\")\n",
    "print(\"< 0.00: Poor agreement\")\n",
    "print(\"0.00-0.20: Slight agreement\")\n",
    "print(\"0.21-0.40: Fair agreement\")\n",
    "print(\"0.41-0.60: Moderate agreement\")\n",
    "print(\"0.61-0.80: Substantial agreement\")\n",
    "print(\"0.81-1.00: Almost perfect agreement\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating examples...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Example 1:\n",
      "User: What's a good Chinese restaurant in San Francisco?\n",
      "Assistant: I recommend China Live in Chinatown. It's known for its excellent dim sum, modern atmosphere, and authentic dishes. The prices are moderate, and they're located at 644 Broadway.\n",
      "Judge Score: 4\n",
      "Golden Score: 5\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Example 2:\n",
      "User: Where can I get good pizza in NYC?\n",
      "Assistant: Sorry, I don't have access to restaurant information.\n",
      "Judge Score: 1\n",
      "Golden Score: 1\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Example 3:\n",
      "User: What's a good Mexican restaurant in Chicago?\n",
      "Assistant: There's a Mexican restaurant downtown.\n",
      "Judge Score: 1\n",
      "Golden Score: 2\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Example 4:\n",
      "User: Recommend an Italian restaurant in Boston.\n",
      "Assistant: Giacomo's in the North End is a popular Italian restaurant. They serve pasta and seafood.\n",
      "Judge Score: 4\n",
      "Golden Score: 3\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Example 5:\n",
      "User: What's a good sushi place in LA?\n",
      "Assistant: Nobu Malibu is an excellent sushi restaurant with ocean views. They're known for their fresh fish and signature dishes, though they are on the expensive side.\n",
      "Judge Score: 3.5\n",
      "Golden Score: 4\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Results Summary:\n",
      "Number of examples evaluated: 5\n",
      "Cohen's Kappa Score: 0.000\n",
      "\n",
      "Interpretation of Kappa Score:\n",
      "< 0.00: Poor agreement\n",
      "0.00-0.20: Slight agreement\n",
      "0.21-0.40: Fair agreement\n",
      "0.41-0.60: Moderate agreement\n",
      "0.61-0.80: Substantial agreement\n",
      "0.81-1.00: Almost perfect agreement\n"
     ]
    }
   ],
   "execution_count": 50
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Routing"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Let's start with the base model. You could access the base model via OpenAI client using Martian endpoint"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T17:24:42.829262Z",
     "start_time": "2025-05-23T17:24:42.776026Z"
    }
   },
   "source": [
    "# TODO change to enum from SDK\n",
    "base_model = \"openai/openai/gpt-4o\"\n",
    "openai_client = openai.OpenAI(\n",
    "    api_key=config.api_key,\n",
    "    base_url=config.api_url + \"/openai/v2\"\n",
    ")\n",
    "# Prepare the OpenAI chat completion request\n",
    "openai_completion_request = {\n",
    "    \"model\": \"openai/openai/gpt-4o-mini\",\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": chat_request_text\n",
    "        }\n",
    "    ],\n",
    "    \"max_tokens\": 100\n",
    "}\n",
    "openai_completion_request"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 'openai/openai/gpt-4o-mini',\n",
       " 'messages': [{'role': 'user',\n",
       "   'content': 'What is a good Chinese restaurant in downtown San Francisco?'}],\n",
       " 'max_tokens': 100}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T17:24:46.950223Z",
     "start_time": "2025-05-23T17:24:44.715979Z"
    }
   },
   "cell_type": "code",
   "source": [
    "response = openai_client.chat.completions.create(\n",
    "    **openai_completion_request\n",
    ")\n",
    "response.llm_response['choices'][0]['message']"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': \"One highly recommended Chinese restaurant in downtown San Francisco is **Yank Sing**. It's well-known for its dim sum and offers a variety of traditional dishes in a stylish setting. Another popular option is **R&G Lounge**, which is famous for its salt and pepper crab and other Cantonese dishes. Both restaurants are praised for their quality food and vibrant atmosphere. Be sure to check their hours and make a reservation if needed, as they can get quite busy!\",\n",
       " 'refusal': None,\n",
       " 'role': 'assistant',\n",
       " 'annotations': [],\n",
       " 'audio': None,\n",
       " 'function_call': None,\n",
       " 'tool_calls': None}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T17:24:49.543519Z",
     "start_time": "2025-05-23T17:24:49.537110Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# You could see the cost of the llm request\n",
    "response.llm_response['cost']"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.73e-05"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T17:25:25.861246Z",
     "start_time": "2025-05-23T17:25:25.858631Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Now, let's create a router\n",
    "router_id = \"restaurant-recommendation-router\"\n",
    "router = client.routers.create_router(router_id, base_model,\n",
    "                                      description=\"It's a brand new router to select the best model on restaurant recommendations.\")"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T17:25:11.543788Z",
     "start_time": "2025-05-23T17:25:11.522611Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# You could list all your routers\n",
    "all_routers = client.routers.list()\n",
    "print(\"Routers:\")\n",
    "print(*[f\"\\t- {r}\\n\" for r in all_routers])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Routers:\n",
      "\t- Router(id='restaurant-recommendation-router', version=1, description=\"It's a brand new router to select the best model on restaurant recommendations.\", createTime='2025-05-23T17:19:54.252429Z', name='organizations/68275a4af88f39d6440c1050/routers/restaurant-recommendation-router', routerSpec=None)\n",
      " \t- Router(id='new-super-router-id', version=73, description=\"It's a new cool router\", createTime='2025-05-23T15:40:14.051683Z', name='organizations/68275a4af88f39d6440c1050/routers/new-super-router-id', routerSpec=None)\n",
      " \t- Router(id='new-super-router-is', version=1, description=\"It's a new cool router\", createTime='2025-05-22T20:20:14.657673Z', name='organizations/68275a4af88f39d6440c1050/routers/new-super-router-is', routerSpec=None)\n",
      " \t- Router(id='new-super-router', version=1, description=\"It's a new cool router\", createTime='2025-05-22T20:16:53.097515Z', name='organizations/68275a4af88f39d6440c1050/routers/new-super-router', routerSpec=None)\n",
      " \t- Router(id='quality-cost-router', version=1, description='A router that balances quality and cost', createTime='2025-05-22T19:41:16.597924Z', name='organizations/68275a4af88f39d6440c1050/routers/quality-cost-router', routerSpec=None)\n",
      " \t- Router(id='predictor-router', version=1, description='A router that balances quality and cost', createTime='2025-05-22T19:11:14.842478Z', name='organizations/68275a4af88f39d6440c1050/routers/predictor-router', routerSpec=None)\n",
      "\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T17:25:31.276992Z",
     "start_time": "2025-05-23T17:25:31.251315Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Getting router by id\n",
    "retrieved_router = client.routers.get(router_id)\n",
    "print(f\"\\nRetrieved router: {retrieved_router}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Retrieved router: Router(id='restaurant-recommendation-router', version=1, description=\"It's a brand new router to select the best model on restaurant recommendations.\", createTime='2025-05-23T17:19:54.252429Z', name='organizations/68275a4af88f39d6440c1050/routers/restaurant-recommendation-router', routerSpec={'points': [{'point': {'x': 0, 'y': 0}, 'executor': {'spec': {'executor_type': 'ModelExecutor', 'model_name': 'openai/openai/gpt-4o'}}}, {'point': {'x': 1, 'y': 1}, 'executor': {'spec': {'executor_type': 'ModelExecutor', 'model_name': 'openai/openai/gpt-4o'}}}]})\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Before the router is trained, it will use the base model for inference\n",
    "\n",
    "To run the router:\n",
    "- change the model name in the request into the router name,\n",
    "- add routing constrains"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T17:39:50.807261Z",
     "start_time": "2025-05-23T17:39:50.803580Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# cost routing constrains\n",
    "cost_constraint = RouterConstraints.RoutingConstraint(\n",
    "    cost_constraint=RouterConstraints.CostConstraint(\n",
    "        value=RouterConstraints.ConstraintValue(numeric_value=0.5)\n",
    "    )\n",
    ")\n",
    "cost_constraint"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RoutingConstraint(cost_constraint=CostConstraint(value=ConstraintValue(numeric_value=0.5, model_name=None)), quality_constraint=None)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T17:45:39.501287Z",
     "start_time": "2025-05-23T17:45:39.495214Z"
    }
   },
   "cell_type": "code",
   "source": [
    "router_completion_request = openai_completion_request | {\n",
    "    \"model\": retrieved_router.name  # using router name instead of base model name\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T17:46:50.755155Z",
     "start_time": "2025-05-23T17:46:48.708893Z"
    }
   },
   "cell_type": "code",
   "source": [
    "router_response = openai_client.chat.completions.create(\n",
    "    **router_completion_request,\n",
    "    extra_body={\n",
    "        RouterConstraints.ROUTING_CONSTRAINT_KEY: cost_constraint.to_dict()\n",
    "        # adding cost routing constraint to the request\n",
    "    }\n",
    ")\n",
    "router_response.llm_response['choices'][0]['message']"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': \"Downtown San Francisco offers a variety of excellent Chinese restaurants. Some popular choices include:\\n\\n1. **Hunan Home's Restaurant**: Located in Chinatown, it is renowned for its authentic Hunan and Szechuan-style dishes.\\n\\n2. **Chong Qing Xiao Mian**: Known for its flavorful and spicy Chongqing noodles and a wide range of traditional Sichuan dishes.\\n\\n3. **R&G Lounge**: Famous for its salt and pepper crab and a favorite for both locals and tourists.\\n\\n\",\n",
       " 'refusal': None,\n",
       " 'role': 'assistant',\n",
       " 'annotations': [],\n",
       " 'audio': None,\n",
       " 'function_call': None,\n",
       " 'tool_calls': None}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T17:46:50.808504Z",
     "start_time": "2025-05-23T17:46:50.802673Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# You could see the cost and llm model used\n",
    "print(f\"Request cost: {router_response.llm_response['cost']}\")\n",
    "print(f\"Request router to model: {router_response.llm_response['model']}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request cost: 0.001045\n",
      "Request router to model: gpt-4o-2024-08-06\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Let's evaluate the router response\n",
    "client.judges.evaluate_judge(retrieved_judge, router_completion_request, router_response)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Training router"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# TODO"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
