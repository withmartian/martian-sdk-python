{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Martian SDK Quickstart Guide"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T15:05:59.288307Z",
     "start_time": "2025-05-26T15:05:59.282653Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Imports\n",
    "import openai\n",
    "from openai.types.chat import (\n",
    "    chat_completion,\n",
    "    chat_completion_message,\n",
    ")\n",
    "\n",
    "from martian_apart_hack_sdk import judge_specs, martian_client, utils\n",
    "from martian_apart_hack_sdk.models import RouterConstraints"
   ],
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Load Credentials\n",
    "You must have a .env file with the following values set:\n",
    "\n",
    "1. `MARTIAN_API_URL` - withmartian.com/api\n",
    "1. `MARTIAN_ORG_ID` - your Martain organization ID\n",
    "1. `MARTIAN_API_KEY` - your personal API key"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T14:50:03.611700Z",
     "start_time": "2025-05-26T14:50:03.607431Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the config and make a client.\n",
    "config = utils.load_config()\n",
    "client = martian_client.MartianClient(\n",
    "    api_url=config.api_url,\n",
    "    api_key=config.api_key,\n",
    "    org_id=config.org_id,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Martian Gateway\n",
    "\n",
    "You can use Martian as a gateway to access a number of different LLM providers.\n",
    "To do so, you start by making an OpenAI client with the base_url set to the Martian API URL + \"/openai/v2\".\n",
    "Then you can use the client as you would when working with OpenAI.\n",
    "\n",
    "The list of available models are:\n",
    "\n",
    "- gpt-4.5-preview\n",
    "- gpt-4.1\n",
    "- gpt-4.1-mini\n",
    "- gpt-4.1-nano\n",
    "- gpt-4o\n",
    "- gpt-4o-mini\n",
    "- o3-mini\n",
    "\n",
    "- claude-3-opus-latest\n",
    "- claude-3-5-haiku-latest\n",
    "- claude-3-5-sonnet-latest\n",
    "- claude-3-7-sonnet-latest\n",
    "\n",
    "- together/deepseek-ai/DeepSeek-R1\n",
    "- together/deepseek-ai/DeepSeek-V3\n",
    "- together/mistralai/Mistral-Small-24B-Instruct-2501\n",
    "- together/nvidia/Llama-3.1-Nemotron-70B-Instruct-HF\n",
    "- together/meta-llama/Llama-3.3-70B-Instruct-Turbo\n",
    "- together/meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo\n",
    "- together/Qwen/Qwen2.5-72B-Instruct-Turbo\n",
    "- together/Qwen/Qwen2.5-Coder-32B-Instruct\n",
    "- together/google/gemma-2-27b-it"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T14:56:05.871507Z",
     "start_time": "2025-05-26T14:56:02.212196Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create the client.\n",
    "openai_client = openai.OpenAI(\n",
    "    api_key=config.api_key,\n",
    "    base_url=config.api_url + \"/openai/v2\"\n",
    ")\n",
    "\n",
    "# Create a request.\n",
    "gpt_nano_chat_completion_response = openai_client.chat.completions.create(\n",
    "    model=\"gpt-4.1-nano\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"What is the capital of France?\"}],\n",
    ")\n",
    "claude_3_haiku_chat_completion_response = openai_client.chat.completions.create(\n",
    "    model=\"claude-3-5-haiku-latest\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"What is the capital of France?\"}],\n",
    ")\n",
    "gemma_2_chat_completion_response = openai_client.chat.completions.create(\n",
    "    model=\"together/google/gemma-2-27b-it\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"What is the capital of France?\"}],\n",
    ")\n",
    "\n",
    "# Get the response.\n",
    "print(\"gpt-4.1-nano says:\", gpt_nano_chat_completion_response.choices[0].message.content)\n",
    "print(\"claude-3-5-haiku-latest says:\", claude_3_haiku_chat_completion_response.choices[0].message.content)\n",
    "print(\"gemma-2-27b-it says:\", gemma_2_chat_completion_response.choices[0].message.content)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-4.1-nano says: The capital of France is Paris.\n",
      "claude-3-5-haiku-latest says: The capital of France is Paris.\n",
      "gemma-2-27b-it says: The capital of France is **Paris**. ðŸ‡«ðŸ‡· \n",
      "\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Judging"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "To create a basic rubric-based judge with a numeric scoring model, you just need to provide the rubric, the minimum and maximum scores, and the model you'd like to use as the judge.\n",
    "\n",
    "MARTIAN'S TIP: It's better to use discrete numbersâ€”and, if possible, a binary scaleâ€”to minimize potential biases."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T14:56:49.109101Z",
     "start_time": "2025-05-26T14:56:49.098441Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create a JudgeSpec\n",
    "\n",
    "rubric = \"\"\"\n",
    "You are tasked with evaluating whether a restaurant recommendation is good.\n",
    "The scoring is as follows:\n",
    "- 1: If the recommendation doesn't meet any of the criteria.\n",
    "- 2: If the recommendation meets only some small part of the criteria.\n",
    "- 3: If the recommendation is reasonable, but not perfect.\n",
    "- 4: If the recommendation is almost perfect.\n",
    "- 5: If the recommendation is perfect.\n",
    "\"\"\".strip()\n",
    "\n",
    "rubric_judge_spec = judge_specs.RubricJudgeSpec(\n",
    "    model_type=\"rubric_judge\",\n",
    "    rubric=rubric,\n",
    "    model=\"openai/openai/gpt-4o\",\n",
    "    min_score=1,\n",
    "    max_score=5,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T14:56:54.646398Z",
     "start_time": "2025-05-26T14:56:51.416589Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Run the judge spec.\n",
    "\n",
    "chat_request_text = \"What is a good Chinese restaurant in downtown San Francisco?\"\n",
    "chat_response_text = \"I couldn't find a good Mexican restaurant near you.\"\n",
    "\n",
    "completion_request = {\n",
    "    \"model\": \"openai/openai/gpt-4o-mini\",\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": chat_request_text}],\n",
    "}\n",
    "chat_completion_response = chat_completion.ChatCompletion(\n",
    "    id=\"123\",\n",
    "    choices=[\n",
    "        chat_completion.Choice(\n",
    "            finish_reason=\"stop\",\n",
    "            index=0,\n",
    "            message=chat_completion_message.ChatCompletionMessage(\n",
    "                role=\"assistant\",\n",
    "                content=chat_response_text,\n",
    "            ),\n",
    "        )\n",
    "    ],\n",
    "    created=0,\n",
    "    model=\"gpt-4o\",\n",
    "    object=\"chat.completion\",\n",
    "    service_tier=None,\n",
    ")\n",
    "\n",
    "evaluation_result = client.judges.evaluate_judge_spec(\n",
    "    rubric_judge_spec.to_dict(),\n",
    "    completion_request=completion_request,\n",
    "    completion_response=chat_completion_response,\n",
    ")\n",
    "\n",
    "print(f\"User: {chat_request_text}\")\n",
    "print(f\"Assistant: {chat_response_text}\")\n",
    "print(f\"Evaluation result: {evaluation_result}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: What is a good Chinese restaurant in downtown San Francisco?\n",
      "Assistant: I couldn't find a good Mexican restaurant near you.\n",
      "Evaluation result: JudgeEvaluation(score=1, reason=\"\\nThe assistant's response does not meet the user's request at all. The user specifically asked for a recommendation for a Chinese restaurant in downtown San Francisco, but the assistant responded about not finding a Mexican restaurant. This indicates a lack of relevance and does not address the user's query in any capacity. According to the rubric, this response doesn't meet any of the criteria for a good recommendation, which results in the lowest possible score.\\n\", cost=0.0016425)\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Once you're satisfied with the judge, you can save it."
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T14:56:56.399664Z",
     "start_time": "2025-05-26T14:56:56.299285Z"
    }
   },
   "cell_type": "code",
   "source": [
    "judge_id = \"restaurant-recommendation-reviewer\"\n",
    "\n",
    "judge = client.judges.get(judge_id=judge_id)\n",
    "if judge is None:\n",
    "    judge = client.judges.create_judge(\n",
    "        judge_id=judge_id,\n",
    "        judge_spec=rubric_judge_spec,\n",
    "        description=\"A judge that rates how good restaurant recommendations are.\"\n",
    "    )\n",
    "    print(f\"Created a judge: {judge}\")\n",
    "else:\n",
    "    print(f\"Judge {judge_id} already exists. Skipping creation.\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Judge restaurant-recommendation-reviewer already exists. Skipping creation.\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "You can now also evaluate the judge by its ID."
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T14:57:00.459513Z",
     "start_time": "2025-05-26T14:56:58.777421Z"
    }
   },
   "cell_type": "code",
   "source": [
    "evaluation_result = client.judges.evaluate_judge(\n",
    "    judge,\n",
    "    completion_request=completion_request,\n",
    "    completion_response=chat_completion_response,\n",
    ")\n",
    "\n",
    "print(f\"Judge response: {evaluation_result}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Judge response: JudgeEvaluation(score=1, reason=\"\\nThe assistant's response does not meet any of the criteria for a good recommendation because it fails to provide a relevant suggestion. The user asked specifically for a Chinese restaurant in downtown San Francisco, but the assistant mistakenly mentioned not finding a Mexican restaurant, which is not relevant to the user's query. Therefore, the recommendation is not applicable to the user's request for information.\\n\", cost=0.0015225)\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Once you have created some judges, you may want to list them all"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T14:57:35.488825Z",
     "start_time": "2025-05-26T14:57:35.478086Z"
    }
   },
   "cell_type": "code",
   "source": [
    "all_judges = client.judges.list()\n",
    "print(\"Judges:\")\n",
    "print(*[f\"\\t- {j}\\n\" for j in all_judges])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Judges:\n",
      "\t- Judge(id='my-rubric-judge', version=18, description='', createTime='2025-05-26T14:49:06.634150Z', name='organizations/68275a4af88f39d6440c1050/judges/my-rubric-judge', judgeSpec=None)\n",
      " \t- Judge(id='restaurant-recommendation-reviewer-extended', version=1, description='A judge that rates how helpful the question for the target is', createTime='2025-05-23T20:04:22.152450Z', name='organizations/68275a4af88f39d6440c1050/judges/restaurant-recommendation-reviewer-extended', judgeSpec=None)\n",
      " \t- Judge(id='restaurant-recommendation-reviewer', version=4, description='A judge that rates how good restaurant recommendations are.', createTime='2025-05-23T20:02:34.730158Z', name='organizations/68275a4af88f39d6440c1050/judges/restaurant-recommendation-reviewer', judgeSpec=None)\n",
      "\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "If you already know the ID, you can retrieve the judge."
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T14:57:54.282024Z",
     "start_time": "2025-05-26T14:57:54.254337Z"
    }
   },
   "cell_type": "code",
   "source": [
    "retrieved_judge = client.judges.get(\n",
    "    judge_id=\"restaurant-recommendation-reviewer\",\n",
    "    version=1,\n",
    ")\n",
    "print(f\"\\nRetrieved judge: {retrieved_judge}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Retrieved judge: Judge(id='restaurant-recommendation-reviewer', version=1, description='A judge that rates how good restaurant recommendations are.', createTime='2025-05-23T15:52:53.326120Z', name='organizations/68275a4af88f39d6440c1050/judges/restaurant-recommendation-reviewer', judgeSpec={'extract_judgement': {'extraction_fields': [{'extraction_pattern': '<rationale>(.*?)</rationale>', 'field_type': 'STRING', 'match_index': -1, 'name': 'rationale', 'required': True}, {'extraction_pattern': '<score>(.*?)</score>', 'field_type': 'FLOAT', 'match_index': -1, 'name': 'score', 'required': True}], 'model_type': 'regex_extractor'}, 'extract_variables': {'extraction_fields': [{'extraction_pattern': '', 'field_type': 'STRING', 'match_index': 0, 'name': 'content', 'required': True}], 'model_type': 'default_extractor'}, 'max_score': 5, 'min_score': 1, 'model': 'openai/openai/gpt-4o', 'model_type': 'rubric_judge', 'postscript': \"Here's the conversation you are judging:\\n<content>\\n${content}\\n</content>\\n\\nPlease evaluate the assistant's response in the conversation above according to the rubric.\\nThink step-by-step to produce a score, and please provide a rationale for your score.\\nYour score should be between ${min_score} and ${max_score}.\\n\\nYour response MUST include:\\n1. A <rationale>...</rationale> tag containing your explanation\\n2. A <score>...</score> tag containing your numerical score\\n\", 'prescript': 'You are a helpful assistant that scores responses between ${min_score} and ${max_score} according to the following rubric:', 'rubric': \"You are tasked with evaluating whether a restaurant recommendation is good.\\nThe scoring is as follows:\\n- 1: If the recommendation doesn't meet any of the criteria.\\n- 2: If the recommendation meets only some small part of the criteria.\\n- 3: If the recommendation is reasonable, but not perfect.\\n- 4: If the recommendation is almost perfect.\\n- 5: If the recommendation is perfect.\"})\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Or you can update the judge to create a new version.\n",
    "\n",
    "MARTIAN TIP: Judges are immutable, so there's no risk of breaking anything when you update. For example, if your current production setup is using version 2 and you update the judge, it will simply create version 3 without affecting your existing production environment."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T14:57:59.764751Z",
     "start_time": "2025-05-26T14:57:59.722260Z"
    }
   },
   "cell_type": "code",
   "source": [
    "new_rubric = \"\"\"\n",
    "You are tasked with evaluating whether a restaurant recommendation is good.\n",
    "The scoring is as follows:\n",
    "- 1: If the recommendation doesn't meet any of the criteria.\n",
    "- 2: If the recommendation meets only some small part of the criteria.\n",
    "- 3: If the recommendation is reasonable, but not perfect.\n",
    "- 4: If the recommendation is almost perfect.\n",
    "- 5: If the recommendation is perfect.\n",
    "\"\"\".strip()\n",
    "\n",
    "new_rubric_judge_spec = judge_specs.RubricJudgeSpec(\n",
    "    model_type=\"rubric_judge\",\n",
    "    rubric=rubric,\n",
    "    # TODO: Clearly communicate which models are available.\n",
    "    model=\"openai/openai/gpt-4o\",\n",
    "    min_score=1,\n",
    "    max_score=5,\n",
    ")\n",
    "\n",
    "new_judge_spec = client.judges.update_judge(\n",
    "    judge_id=\"restaurant-recommendation-reviewer\",\n",
    "    judge_spec=new_rubric_judge_spec,\n",
    ")\n",
    "\n",
    "print(f\"\\nNew judge spec: {new_judge_spec}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New judge spec: Judge(id='restaurant-recommendation-reviewer', version=5, description='A judge that rates how good restaurant recommendations are.', createTime='2025-05-26T14:57:59.746789Z', name='organizations/68275a4af88f39d6440c1050/judges/restaurant-recommendation-reviewer', judgeSpec={'extract_judgement': {'extraction_fields': [{'extraction_pattern': '<rationale>(.*?)</rationale>', 'field_type': 'STRING', 'match_index': -1, 'name': 'rationale', 'required': True}, {'extraction_pattern': '<score>(.*?)</score>', 'field_type': 'FLOAT', 'match_index': -1, 'name': 'score', 'required': True}], 'model_type': 'regex_extractor'}, 'extract_variables': {'extraction_fields': [{'extraction_pattern': '', 'field_type': 'STRING', 'match_index': 0, 'name': 'content', 'required': True}], 'model_type': 'default_extractor'}, 'max_score': 5, 'min_score': 1, 'model': 'openai/openai/gpt-4o', 'model_type': 'rubric_judge', 'postscript': \"Here's the conversation you are judging:\\n<content>\\n${content}\\n</content>\\n\\nPlease evaluate the assistant's response in the conversation above according to the rubric.\\nThink step-by-step to produce a score, and please provide a rationale for your score.\\nYour score should be between ${min_score} and ${max_score}.\\n\\nYour response MUST include:\\n1. A <rationale>...</rationale> tag containing your explanation\\n2. A <score>...</score> tag containing your numerical score\\n\", 'prescript': 'You are a helpful assistant that scores responses between ${min_score} and ${max_score} according to the following rubric:', 'rubric': \"You are tasked with evaluating whether a restaurant recommendation is good.\\nThe scoring is as follows:\\n- 1: If the recommendation doesn't meet any of the criteria.\\n- 2: If the recommendation meets only some small part of the criteria.\\n- 3: If the recommendation is reasonable, but not perfect.\\n- 4: If the recommendation is almost perfect.\\n- 5: If the recommendation is perfect.\"})\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Example of a More Complex Judge\n",
    "We can start with a specification that includes not only the rubric but also a customized prescript (which is added to the judge prompt before the rubric) and postscript (which goes after the rubric). This setup is typically used to customize how your judge processes requests."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T20:02:37.944272Z",
     "start_time": "2025-05-23T20:02:37.936074Z"
    }
   },
   "cell_type": "code",
   "source": "json_spec = '{\\n  \"model_type\": \"rubric_judge\",\\n  \"rubric\": \"Is important question helps to advance to the target?\",\\n  \"model\": \"gpt-4o-mini\",\\n  \"min_score\": 1.0,\\n  \"max_score\": 4.0,\\n  \"prescript\": \"target of the conversation: ${target}.\\\\nConversation: ${conversation}.important question: ${important_question}.\\\\n\\\\n\",\\n  \"postscript\": \"Please evaluate conversation according to the rubric.\\\\nThink step-by-step to produce a score, and please provide a rationale for your score.\\\\nYour score should be between ${min_score} and ${max_score}.\\\\n\\\\nYour response MUST include:\\\\n1. A <rationale>...</rationale> tag containing your explanation\\\\n2. A <score>...</score> tag containing your numerical score\\\\n\",\\n  \"extract_variables\": {\\n    \"model_type\": \"combined_extractor\",\\n    \"extraction_fields\": [\\n      {\\n        \"name\": \"target\",\\n        \"field_type\": \"STRING\",\\n        \"required\": true,\\n        \"extraction_pattern\": \"\\\\\"target\\\\\":\\\\\"([\\\\\\\\S\\\\\\\\s]*?)\\\\\"\",\\n        \"match_index\": 0\\n      },\\n      {\\n        \"name\": \"important_question\",\\n        \"field_type\": \"STRING\",\\n        \"required\": true,\\n        \"extraction_pattern\": \"\\\\\"important\\\\\", \\\\\"question\\\\\": \\\\\"([\\\\\\\\s\\\\\\\\S]*?)\\\\\"\",\\n        \"match_index\": -1\\n      },\\n      {\\n        \"name\": \"conversation\",\\n        \"field_type\": \"STRING\",\\n        \"required\": true,\\n        \"extraction_pattern\": null,\\n        \"match_index\": 0\\n      }\\n    ],\\n    \"extractors\": [\\n      {\\n        \"model_type\": \"regex_extractor\",\\n        \"extraction_fields\": [\\n          {\\n            \"name\": \"target\",\\n            \"field_type\": \"STRING\",\\n            \"required\": true,\\n            \"extraction_pattern\": \"\\\\\"target\\\\\":\\\\\"([\\\\\\\\S\\\\\\\\s]*?)\\\\\"\",\\n            \"match_index\": 0\\n          }\\n        ]\\n      },\\n      {\\n        \"model_type\": \"response_regex_extractor\",\\n        \"extraction_fields\": [\\n          {\\n            \"name\": \"important_question\",\\n            \"field_type\": \"STRING\",\\n            \"required\": true,\\n            \"extraction_pattern\": \"\\\\\"important\\\\\", \\\\\"question\\\\\": \\\\\"([\\\\\\\\s\\\\\\\\S]*?)\\\\\"\",\\n            \"match_index\": -1\\n          }\\n        ]\\n      },\\n      {\\n        \"model_type\": \"conversation_extractor\",\\n        \"extraction_fields\": [\\n          {\\n            \"name\": \"conversation\",\\n            \"field_type\": \"STRING\",\\n            \"required\": true,\\n            \"extraction_pattern\": null,\\n            \"match_index\": 0\\n          }\\n        ]\\n      }\\n    ]\\n  },\\n  \"extract_judgement\": {\\n    \"model_type\": \"regex_extractor\",\\n    \"extraction_fields\": [\\n      {\\n        \"name\": \"rationale\",\\n        \"field_type\": \"STRING\",\\n        \"required\": true,\\n        \"extraction_pattern\": \"<rationale>(.*?)</rationale>\",\\n        \"match_index\": -1\\n      },\\n      {\\n        \"name\": \"score\",\\n        \"field_type\": \"FLOAT\",\\n        \"required\": true,\\n        \"extraction_pattern\": \"<score>(.*?)</score>\",\\n        \"match_index\": -1\\n      }\\n    ]\\n  }\\n}'",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T20:02:39.769576Z",
     "start_time": "2025-05-23T20:02:39.756037Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "json.loads(json_spec)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_type': 'rubric_judge',\n",
       " 'rubric': 'Is important question helps to advance to the target?',\n",
       " 'model': 'gpt-4o-mini',\n",
       " 'min_score': 1.0,\n",
       " 'max_score': 4.0,\n",
       " 'prescript': 'target of the conversation: ${target}.\\nConversation: ${conversation}.important question: ${important_question}.\\n\\n',\n",
       " 'postscript': 'Please evaluate conversation according to the rubric.\\nThink step-by-step to produce a score, and please provide a rationale for your score.\\nYour score should be between ${min_score} and ${max_score}.\\n\\nYour response MUST include:\\n1. A <rationale>...</rationale> tag containing your explanation\\n2. A <score>...</score> tag containing your numerical score\\n',\n",
       " 'extract_variables': {'model_type': 'combined_extractor',\n",
       "  'extraction_fields': [{'name': 'target',\n",
       "    'field_type': 'STRING',\n",
       "    'required': True,\n",
       "    'extraction_pattern': '\"target\":\"([\\\\S\\\\s]*?)\"',\n",
       "    'match_index': 0},\n",
       "   {'name': 'important_question',\n",
       "    'field_type': 'STRING',\n",
       "    'required': True,\n",
       "    'extraction_pattern': '\"important\", \"question\": \"([\\\\s\\\\S]*?)\"',\n",
       "    'match_index': -1},\n",
       "   {'name': 'conversation',\n",
       "    'field_type': 'STRING',\n",
       "    'required': True,\n",
       "    'extraction_pattern': None,\n",
       "    'match_index': 0}],\n",
       "  'extractors': [{'model_type': 'regex_extractor',\n",
       "    'extraction_fields': [{'name': 'target',\n",
       "      'field_type': 'STRING',\n",
       "      'required': True,\n",
       "      'extraction_pattern': '\"target\":\"([\\\\S\\\\s]*?)\"',\n",
       "      'match_index': 0}]},\n",
       "   {'model_type': 'response_regex_extractor',\n",
       "    'extraction_fields': [{'name': 'important_question',\n",
       "      'field_type': 'STRING',\n",
       "      'required': True,\n",
       "      'extraction_pattern': '\"important\", \"question\": \"([\\\\s\\\\S]*?)\"',\n",
       "      'match_index': -1}]},\n",
       "   {'model_type': 'conversation_extractor',\n",
       "    'extraction_fields': [{'name': 'conversation',\n",
       "      'field_type': 'STRING',\n",
       "      'required': True,\n",
       "      'extraction_pattern': None,\n",
       "      'match_index': 0}]}]},\n",
       " 'extract_judgement': {'model_type': 'regex_extractor',\n",
       "  'extraction_fields': [{'name': 'rationale',\n",
       "    'field_type': 'STRING',\n",
       "    'required': True,\n",
       "    'extraction_pattern': '<rationale>(.*?)</rationale>',\n",
       "    'match_index': -1},\n",
       "   {'name': 'score',\n",
       "    'field_type': 'FLOAT',\n",
       "    'required': True,\n",
       "    'extraction_pattern': '<score>(.*?)</score>',\n",
       "    'match_index': -1}]}}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T20:04:22.160786Z",
     "start_time": "2025-05-23T20:04:22.106947Z"
    }
   },
   "cell_type": "code",
   "source": [
    "judge_id = \"restaurant-recommendation-reviewer-extended\"\n",
    "judge = client.judges.get(judge_id=judge_id)\n",
    "if judge is None:\n",
    "    judge = client.judges.create_judge(\n",
    "        judge_id=judge_id,\n",
    "        judge_spec=json.loads(json_spec),\n",
    "        description=\"A judge that rates how helpful the question for the target is\"\n",
    "    )\n",
    "    print(f\"Created a judge: {judge}\")\n",
    "else:\n",
    "    print(f\"Judge {judge_id} already exists. Skipping creation.\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created a judge: Judge(id='restaurant-recommendation-reviewer-extended', version=1, description='A judge that rates how helpful the question for the target is', createTime='2025-05-23T20:04:22.152450Z', name='organizations/68275a4af88f39d6440c1050/judges/restaurant-recommendation-reviewer-extended', judgeSpec={'extract_judgement': {'extraction_fields': [{'extraction_pattern': '<rationale>(.*?)</rationale>', 'field_type': 'STRING', 'match_index': -1, 'name': 'rationale', 'required': True}, {'extraction_pattern': '<score>(.*?)</score>', 'field_type': 'FLOAT', 'match_index': -1, 'name': 'score', 'required': True}], 'model_type': 'regex_extractor'}, 'extract_variables': {'extraction_fields': [{'extraction_pattern': '\"target\":\"([\\\\S\\\\s]*?)\"', 'field_type': 'STRING', 'match_index': 0, 'name': 'target', 'required': True}, {'extraction_pattern': '\"important\", \"question\": \"([\\\\s\\\\S]*?)\"', 'field_type': 'STRING', 'match_index': -1, 'name': 'important_question', 'required': True}, {'extraction_pattern': None, 'field_type': 'STRING', 'match_index': 0, 'name': 'conversation', 'required': True}], 'extractors': [{'extraction_fields': [{'extraction_pattern': '\"target\":\"([\\\\S\\\\s]*?)\"', 'field_type': 'STRING', 'match_index': 0, 'name': 'target', 'required': True}], 'model_type': 'regex_extractor'}, {'extraction_fields': [{'extraction_pattern': '\"important\", \"question\": \"([\\\\s\\\\S]*?)\"', 'field_type': 'STRING', 'match_index': -1, 'name': 'important_question', 'required': True}], 'model_type': 'response_regex_extractor'}, {'extraction_fields': [{'extraction_pattern': None, 'field_type': 'STRING', 'match_index': 0, 'name': 'conversation', 'required': True}], 'model_type': 'conversation_extractor'}], 'model_type': 'combined_extractor'}, 'max_score': 4, 'min_score': 1, 'model': 'gpt-4o-mini', 'model_type': 'rubric_judge', 'postscript': 'Please evaluate conversation according to the rubric.\\nThink step-by-step to produce a score, and please provide a rationale for your score.\\nYour score should be between ${min_score} and ${max_score}.\\n\\nYour response MUST include:\\n1. A <rationale>...</rationale> tag containing your explanation\\n2. A <score>...</score> tag containing your numerical score\\n', 'prescript': 'target of the conversation: ${target}.\\nConversation: ${conversation}.important question: ${important_question}.\\n\\n', 'rubric': 'Is important question helps to advance to the target?'})\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Let's test it with an example request and response:"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T20:04:28.674011Z",
     "start_time": "2025-05-23T20:04:28.667206Z"
    }
   },
   "cell_type": "code",
   "source": [
    "completion_request = {\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": 'Help me to get to my target: \"target\":\"solve P=NP\"',\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Pls answer the question\",\n",
    "        },\n",
    "    ]\n",
    "}\n",
    "chat_completion_response = chat_completion.ChatCompletion(\n",
    "    id=\"123\",\n",
    "    choices=[\n",
    "        chat_completion.Choice(\n",
    "            finish_reason=\"stop\",\n",
    "            index=0,\n",
    "            message=chat_completion_message.ChatCompletionMessage(\n",
    "                role=\"assistant\",\n",
    "                content='{\"type\": \"important\", \"question\": \"Would like to use differential equations to solve P=NP?\"}',\n",
    "            ),\n",
    "        )\n",
    "    ],\n",
    "    created=0,\n",
    "    model=\"gpt-4o\",\n",
    "    object=\"chat.completion\",\n",
    "    service_tier=None,\n",
    ")\n"
   ],
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T20:04:35.276456Z",
     "start_time": "2025-05-23T20:04:31.378960Z"
    }
   },
   "cell_type": "code",
   "source": [
    "evaluation_result = client.judges.evaluate_judge(\n",
    "    judge,\n",
    "    completion_request=completion_request,\n",
    "    completion_response=chat_completion_response,\n",
    ")\n",
    "\n",
    "print(f\"Judge response: {evaluation_result}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Judge response: JudgeEvaluation(score=2, reason='In evaluating the conversation, the important question posed by the user about using differential equations to solve P=NP appears to be somewhat off-target. The P=NP problem is a major unsolved question in computer science concerning computational complexity, while differential equations are typically used in modeling continuous change across various scientific and engineering fields. Although there may be abstract or novel approaches that could theoretically connect these two areas, the question as it stands does not directly advance the conversation towards solving P=NP. \\n\\nThus, while the question is interesting, it does not effectively contribute to advancing the target of the conversation, which is to solve P=NP. Consequently, I would rate this conversation a score of 2.0, indicating that while there is some relevance, the connection is tenuous and not particularly constructive.', cost=0.00012705)\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Let's measure the IAA (Inter-Annotator Agreement) of our judge using the gold scores provided by domain experts."
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T20:05:10.448634Z",
     "start_time": "2025-05-23T20:04:43.519445Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import cohen_kappa_score\n",
    "# Define test examples\n",
    "def create_chat_completion(request_text: str, response_text: str) -> chat_completion.ChatCompletion:\n",
    "    \"\"\"Create a ChatCompletion object for testing.\"\"\"\n",
    "    return chat_completion.ChatCompletion(\n",
    "        id=\"test-completion\",\n",
    "        choices=[\n",
    "            chat_completion.Choice(\n",
    "                finish_reason=\"stop\",\n",
    "                index=0,\n",
    "                message=chat_completion_message.ChatCompletionMessage(\n",
    "                    role=\"assistant\",\n",
    "                    content=response_text,\n",
    "                ),\n",
    "            )\n",
    "        ],\n",
    "        created=0,\n",
    "        model=\"gpt-4o\",\n",
    "        object=\"chat.completion\",\n",
    "        service_tier=None,\n",
    "    )\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"request\": \"What's a good Chinese restaurant in San Francisco?\",\n",
    "        \"response\": \"I recommend China Live in Chinatown. It's known for its excellent dim sum, modern atmosphere, and authentic dishes. The prices are moderate, and they're located at 644 Broadway.\",\n",
    "        \"golden_score\": 5  # Perfect recommendation with details\n",
    "    },\n",
    "    {\n",
    "        \"request\": \"Where can I get good pizza in NYC?\",\n",
    "        \"response\": \"Sorry, I don't have access to restaurant information.\",\n",
    "        \"golden_score\": 1  # Completely unhelpful\n",
    "    },\n",
    "    {\n",
    "        \"request\": \"What's a good Mexican restaurant in Chicago?\",\n",
    "        \"response\": \"There's a Mexican restaurant downtown.\",\n",
    "        \"golden_score\": 2  # Very minimal information\n",
    "    },\n",
    "    {\n",
    "        \"request\": \"Recommend an Italian restaurant in Boston.\",\n",
    "        \"response\": \"Giacomo's in the North End is a popular Italian restaurant. They serve pasta and seafood.\",\n",
    "        \"golden_score\": 3  # Basic but reasonable recommendation\n",
    "    },\n",
    "    {\n",
    "        \"request\": \"What's a good sushi place in LA?\",\n",
    "        \"response\": \"Nobu Malibu is an excellent sushi restaurant with ocean views. They're known for their fresh fish and signature dishes, though they are on the expensive side.\",\n",
    "        \"golden_score\": 4  # Almost perfect, but could include location details\n",
    "    }\n",
    "]\n",
    "\n",
    "# Create judge spec\n",
    "rubric = \"\"\"\n",
    "You are tasked with evaluating whether a restaurant recommendation is good.\n",
    "The scoring is as follows:\n",
    "- 1: If the recommendation doesn't meet any of the criteria.\n",
    "- 2: If the recommendation meets only some small part of the criteria.\n",
    "- 3: If the recommendation is reasonable, but not perfect.\n",
    "- 4: If the recommendation is almost perfect.\n",
    "- 5: If the recommendation is perfect.\n",
    "\"\"\".strip()\n",
    "\n",
    "judge_spec = judge_specs.RubricJudgeSpec(\n",
    "    model_type=\"rubric_judge\",\n",
    "    rubric=rubric,\n",
    "    model=\"openai/openai/gpt-4o\",\n",
    "    min_score=1,\n",
    "    max_score=5,\n",
    ")\n",
    "\n",
    "# Evaluate examples\n",
    "judge_scores = []\n",
    "golden_scores = []\n",
    "\n",
    "print(\"\\nEvaluating examples...\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for i, example in enumerate(examples, 1):\n",
    "    # Create completion request and response\n",
    "    completion_request = {\n",
    "        \"model\": \"openai/openai/gpt-4o\",\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": example[\"request\"]}],\n",
    "    }\n",
    "    completion_response = create_chat_completion(example[\"request\"], example[\"response\"])\n",
    "\n",
    "    # Get judge's evaluation\n",
    "    evaluation = client.judges.evaluate_judge_spec(\n",
    "        judge_spec.to_dict(),\n",
    "        completion_request=completion_request,\n",
    "        completion_response=completion_response,\n",
    "    )\n",
    "\n",
    "    judge_scores.append(int(evaluation.score))\n",
    "    golden_scores.append(example[\"golden_score\"])\n",
    "\n",
    "    print(f\"\\nExample {i}:\")\n",
    "    print(f\"User: {example['request']}\")\n",
    "    print(f\"Assistant: {example['response']}\")\n",
    "    print(f\"Judge Score: {evaluation.score}\")\n",
    "    print(f\"Golden Score: {example['golden_score']}\")\n",
    "    #print(f\"Judge Rationale: {evaluation.rationale}\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "# Calculate Cohen's Kappa\n",
    "kappa = cohen_kappa_score(golden_scores, judge_scores)\n",
    "\n",
    "print(\"\\nResults Summary:\")\n",
    "print(f\"Number of examples evaluated: {len(examples)}\")\n",
    "print(f\"Cohen's Kappa Score: {kappa:.3f}\")\n",
    "print(\"\\nInterpretation of Kappa Score:\")\n",
    "print(\"< 0.00: Poor agreement\")\n",
    "print(\"0.00-0.20: Slight agreement\")\n",
    "print(\"0.21-0.40: Fair agreement\")\n",
    "print(\"0.41-0.60: Moderate agreement\")\n",
    "print(\"0.61-0.80: Substantial agreement\")\n",
    "print(\"0.81-1.00: Almost perfect agreement\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating examples...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Example 1:\n",
      "User: What's a good Chinese restaurant in San Francisco?\n",
      "Assistant: I recommend China Live in Chinatown. It's known for its excellent dim sum, modern atmosphere, and authentic dishes. The prices are moderate, and they're located at 644 Broadway.\n",
      "Judge Score: 4.5\n",
      "Golden Score: 5\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Example 2:\n",
      "User: Where can I get good pizza in NYC?\n",
      "Assistant: Sorry, I don't have access to restaurant information.\n",
      "Judge Score: 1\n",
      "Golden Score: 1\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Example 3:\n",
      "User: What's a good Mexican restaurant in Chicago?\n",
      "Assistant: There's a Mexican restaurant downtown.\n",
      "Judge Score: 2\n",
      "Golden Score: 2\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Example 4:\n",
      "User: Recommend an Italian restaurant in Boston.\n",
      "Assistant: Giacomo's in the North End is a popular Italian restaurant. They serve pasta and seafood.\n",
      "Judge Score: 3\n",
      "Golden Score: 3\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Example 5:\n",
      "User: What's a good sushi place in LA?\n",
      "Assistant: Nobu Malibu is an excellent sushi restaurant with ocean views. They're known for their fresh fish and signature dishes, though they are on the expensive side.\n",
      "Judge Score: 4\n",
      "Golden Score: 4\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Results Summary:\n",
      "Number of examples evaluated: 5\n",
      "Cohen's Kappa Score: 0.750\n",
      "\n",
      "Interpretation of Kappa Score:\n",
      "< 0.00: Poor agreement\n",
      "0.00-0.20: Slight agreement\n",
      "0.21-0.40: Fair agreement\n",
      "0.41-0.60: Moderate agreement\n",
      "0.61-0.80: Substantial agreement\n",
      "0.81-1.00: Almost perfect agreement\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Routing"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Let's start with the base model. You could access the base model via OpenAI client using Martian endpoint"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T14:58:30.320321Z",
     "start_time": "2025-05-26T14:58:30.262488Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# TODO change to enum from SDK\n",
    "base_model = \"openai/openai/gpt-4o\"\n",
    "openai_client = openai.OpenAI(\n",
    "    api_key=config.api_key,\n",
    "    base_url=config.api_url + \"/openai/v2\"\n",
    ")\n",
    "# Prepare the OpenAI chat completion request\n",
    "openai_completion_request = {\n",
    "    \"model\": \"openai/openai/gpt-4o-mini\",\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": chat_request_text\n",
    "        }\n",
    "    ],\n",
    "    \"max_tokens\": 100\n",
    "}\n",
    "openai_completion_request"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 'openai/openai/gpt-4o-mini',\n",
       " 'messages': [{'role': 'user',\n",
       "   'content': 'What is a good Chinese restaurant in downtown San Francisco?'}],\n",
       " 'max_tokens': 100}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T14:58:53.956748Z",
     "start_time": "2025-05-26T14:58:50.682995Z"
    }
   },
   "cell_type": "code",
   "source": [
    "response = openai_client.chat.completions.create(\n",
    "    **openai_completion_request\n",
    ")\n",
    "response.choices[0].message.content"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"One popular Chinese restaurant in downtown San Francisco is **Z & Y Restaurant**. It's known for its Sichuan cuisine and offers a variety of flavorful dishes, including spicy noodles and mapo tofu. Another great option is **Hakkasan**, which provides a modern twist on traditional Chinese dishes in an upscale environment. If you're looking for dim sum, **Yank Sing** is a well-regarded choice with a wide selection. Be sure to check current reviews and availability, as restaurants can change over time\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T14:59:03.108931Z",
     "start_time": "2025-05-26T14:59:03.105405Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# You could see the cost of the llm request\n",
    "response.cost"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.269999999999999e-05"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T14:59:09.189148Z",
     "start_time": "2025-05-26T14:59:09.065330Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Now, let's create a router\n",
    "router_id = \"restaurant-recommendation-router\"\n",
    "router = client.routers.get(router_id)\n",
    "if router is None:\n",
    "    router = client.routers.create_router(router_id, base_model,\n",
    "                                      description=\"It's a brand new router to select the best model on restaurant recommendations.\")\n",
    "    print(f\"Created a router: {router}\")\n",
    "else:\n",
    "    print(f\"Router {router_id} already exists. Skipping creation.\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Router restaurant-recommendation-router already exists. Skipping creation.\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T14:59:19.758813Z",
     "start_time": "2025-05-26T14:59:19.741201Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# You could list all your routers\n",
    "all_routers = client.routers.list()\n",
    "print(\"Routers:\")\n",
    "print(*[f\"\\t- {r}\\n\" for r in all_routers])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Routers:\n",
      "\t- Router(id='new-super-router-id', version=77, description=\"It's a new cool router\", createTime='2025-05-26T14:49:17.276744Z', name='organizations/68275a4af88f39d6440c1050/routers/new-super-router-id', routerSpec=None)\n",
      " \t- Router(id='restaurant-recommendation-router', version=1, description=\"It's a brand new router to select the best model on restaurant recommendations.\", createTime='2025-05-23T17:19:54.252429Z', name='organizations/68275a4af88f39d6440c1050/routers/restaurant-recommendation-router', routerSpec=None)\n",
      " \t- Router(id='new-super-router-is', version=1, description=\"It's a new cool router\", createTime='2025-05-22T20:20:14.657673Z', name='organizations/68275a4af88f39d6440c1050/routers/new-super-router-is', routerSpec=None)\n",
      "\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T14:59:25.669123Z",
     "start_time": "2025-05-26T14:59:25.652057Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Getting router by id\n",
    "retrieved_router = client.routers.get(router_id)\n",
    "print(f\"\\nRetrieved router: {retrieved_router}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Retrieved router: Router(id='restaurant-recommendation-router', version=1, description=\"It's a brand new router to select the best model on restaurant recommendations.\", createTime='2025-05-23T17:19:54.252429Z', name='organizations/68275a4af88f39d6440c1050/routers/restaurant-recommendation-router', routerSpec={'points': [{'point': {'x': 0, 'y': 0}, 'executor': {'spec': {'executor_type': 'ModelExecutor', 'model_name': 'openai/openai/gpt-4o'}}}, {'point': {'x': 1, 'y': 1}, 'executor': {'spec': {'executor_type': 'ModelExecutor', 'model_name': 'openai/openai/gpt-4o'}}}]})\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Before the router is trained, it will use the base model for inference\n",
    "\n",
    "To run the router:\n",
    "- change the model name in the request into the router name,\n",
    "- add routing constrains"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T14:59:29.635949Z",
     "start_time": "2025-05-26T14:59:29.627088Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# cost routing constrains\n",
    "cost_constraint = RouterConstraints.RoutingConstraint(\n",
    "    cost_constraint=RouterConstraints.CostConstraint(\n",
    "        value=RouterConstraints.ConstraintValue(numeric_value=0.5)\n",
    "    )\n",
    ")\n",
    "cost_constraint"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RoutingConstraint(cost_constraint=CostConstraint(value=ConstraintValue(numeric_value=0.5, model_name=None)), quality_constraint=None)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T15:04:15.134869Z",
     "start_time": "2025-05-26T15:04:15.129449Z"
    }
   },
   "cell_type": "code",
   "source": [
    "router_completion_request = openai_completion_request | {\n",
    "    \"model\": retrieved_router.name  # using router name instead of base model name\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T15:08:34.759571Z",
     "start_time": "2025-05-26T15:08:31.499869Z"
    }
   },
   "cell_type": "code",
   "source": [
    "router_response = openai_client.chat.completions.create(\n",
    "    **router_completion_request,\n",
    "    extra_body=RouterConstraints.render_extra_body_router_constraint(cost_constraint)\n",
    ")\n",
    "router_response.choices[0].message.content"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Downtown San Francisco has several excellent Chinese restaurants. Here are a few popular ones:\\n\\n1. **Hakkasan** - Known for its upscale dim sum and modern Cantonese dishes, Hakkasan offers a refined dining experience in a stylish setting.\\n\\n2. **City View Restaurant** - A favorite spot for traditional dim sum, City View is known for its delicious and authentic offerings in a bustling and lively atmosphere.\\n\\n3. **House of Nanking** - This restaurant has a bit of a cult'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T15:08:54.795855Z",
     "start_time": "2025-05-26T15:08:54.791152Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# You could see the cost and llm model used\n",
    "print(f\"Request cost: {router_response.cost}\")\n",
    "print(f\"Request router to model: {router_response.model}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request cost: 0.001045\n",
      "Request router to model: gpt-4o-2024-08-06\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T15:09:09.686163Z",
     "start_time": "2025-05-26T15:09:03.085340Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Let's evaluate the router response\n",
    "# TODO: OpenAI  response version was changed, need to be reshaped before sending to the judge\n",
    "client.judges.evaluate_judge(retrieved_judge, router_completion_request, router_response)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "JudgeEvaluation(score=4, reason=\"\\nThe assistant's response provides three recommendations for Chinese restaurants in downtown San Francisco, which addresses the user's question directly. The recommendations include a variety of options: Hakkasan for a refined and upscale experience, City View Restaurant for traditional dim sum in a lively setting, and House of Nanking, which suggests a unique or cult favorite. This covers different styles of Chinese dining, catering to potential different preferences the user might have. However, the response cuts off in the middle of the House of Nanking description, which leaves the recommendation incomplete. Despite this, the assistant has offered a good range of options and seems informed about the locations and specialties of each restaurant. To be perfect, the response would need to be complete and possibly include more fitting details about why each place is a strong choice. Overall, the response is almost perfect but is slightly marred by the incomplete information.\\n\", cost=0.00278)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Training router"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T20:13:21.625188Z",
     "start_time": "2025-05-23T20:13:21.620328Z"
    }
   },
   "cell_type": "code",
   "source": "# TODO",
   "outputs": [],
   "execution_count": 51
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
