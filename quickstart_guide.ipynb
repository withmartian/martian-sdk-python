{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Martian SDK Quickstart Guide"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T19:50:35.180264Z",
     "start_time": "2025-05-23T19:50:35.175072Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Imports\n",
    "import openai\n",
    "from openai.types.chat import (\n",
    "    chat_completion,\n",
    "    chat_completion_message,\n",
    ")\n",
    "\n",
    "from martian_apart_hack_sdk import judge_specs, martian_client, utils\n",
    "from martian_apart_hack_sdk.models import RouterConstraints"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Load Credentials\n",
    "You must have a .env file with the following values set:\n",
    "\n",
    "1. `MARTIAN_API_URL` - withmartian.com/api\n",
    "1. `MARTIAN_ORG_ID` - your Martain organization ID\n",
    "1. `MARTIAN_API_KEY` - your personal API key"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T19:50:36.270053Z",
     "start_time": "2025-05-23T19:50:36.260890Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the config and make a client.\n",
    "config = utils.load_config()\n",
    "client = martian_client.MartianClient(\n",
    "    api_url=config.api_url,\n",
    "    api_key=config.api_key,\n",
    "    org_id=config.org_id,\n",
    ")"
   ],
   "execution_count": 10,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Martian Gateway\n",
    "\n",
    "You can use Martian as a gateway to access a number of different LLM providers.\n",
    "To do so, you start by making an OpenAI client with the base_url set to the Martian API URL + \"/openai/v2\".\n",
    "Then you can use the client as you would when working with OpenAI.\n",
    "\n",
    "The list of available models are:\n",
    "\n",
    "- gpt-4.5-preview\n",
    "- gpt-4.1\n",
    "- gpt-4.1-mini\n",
    "- gpt-4.1-nano\n",
    "- gpt-4o\n",
    "- gpt-4o-mini\n",
    "- o3-mini\n",
    "\n",
    "- claude-3-opus-latest\n",
    "- claude-3-5-haiku-latest\n",
    "- claude-3-5-sonnet-latest\n",
    "- claude-3-7-sonnet-latest\n",
    "\n",
    "- together/deepseek-ai/DeepSeek-R1\n",
    "- together/deepseek-ai/DeepSeek-V3\n",
    "- together/mistralai/Mistral-Small-24B-Instruct-2501\n",
    "- together/nvidia/Llama-3.1-Nemotron-70B-Instruct-HF\n",
    "- together/meta-llama/Llama-3.3-70B-Instruct-Turbo\n",
    "- together/meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo\n",
    "- together/Qwen/Qwen2.5-72B-Instruct-Turbo\n",
    "- together/Qwen/Qwen2.5-Coder-32B-Instruct\n",
    "- together/google/gemma-2-27b-it"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T20:14:34.292611Z",
     "start_time": "2025-05-23T20:14:31.670161Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create the client.\n",
    "openai_client = openai.OpenAI(\n",
    "    api_key=config.api_key,\n",
    "    base_url=config.api_url + \"/openai/v2\"\n",
    ")\n",
    "\n",
    "# Create a request.\n",
    "gpt_nano_chat_completion_response = openai_client.chat.completions.create(\n",
    "    model=\"gpt-4.1-nano\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"What is the capital of France?\"}],\n",
    ")\n",
    "claude_3_haiku_chat_completion_response = openai_client.chat.completions.create(\n",
    "    model=\"claude-3-5-haiku-latest\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"What is the capital of France?\"}],\n",
    ")\n",
    "gemma_2_chat_completion_response = openai_client.chat.completions.create(\n",
    "    model=\"gemma-2-27b-it\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"What is the capital of France?\"}],\n",
    ")\n",
    "\n",
    "# Get the response.\n",
    "print(\"gpt-4.1-nano says:\", gpt_nano_chat_completion_response.llm_response[\"choices\"][0][\"message\"][\"content\"])  # type: ignore\n",
    "print(\"claude-3-5-haiku-latest says:\", claude_3_haiku_chat_completion_response.llm_response[\"choices\"][0][\"message\"][\"content\"])  # type: ignore\n",
    "print(\"gemma-2-27b-it says:\", gemma_2_chat_completion_response.llm_response[\"choices\"][0][\"message\"][\"content\"])  # type: ignore"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-4.1-nano says: The capital of France is Paris.\n",
      "claude-3-5-haiku-latest says: The capital of France is Paris.\n"
     ]
    }
   ],
   "execution_count": 52
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Judging"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "To create a basic rubric-based judge with a numeric scoring model, you just need to provide the rubric, the minimum and maximum scores, and the model you'd like to use as the judge.\n",
    "\n",
    "MARTIAN'S TIP: It's better to use discrete numbers—and, if possible, a binary scale—to minimize potential biases."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T19:58:40.601929Z",
     "start_time": "2025-05-23T19:58:40.595439Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create a JudgeSpec\n",
    "\n",
    "rubric = \"\"\"\n",
    "You are tasked with evaluating whether a restaurant recommendation is good.\n",
    "The scoring is as follows:\n",
    "- 1: If the recommendation doesn't meet any of the criteria.\n",
    "- 2: If the recommendation meets only some small part of the criteria.\n",
    "- 3: If the recommendation is reasonable, but not perfect.\n",
    "- 4: If the recommendation is almost perfect.\n",
    "- 5: If the recommendation is perfect.\n",
    "\"\"\".strip()\n",
    "\n",
    "rubric_judge_spec = judge_specs.RubricJudgeSpec(\n",
    "    model_type=\"rubric_judge\",\n",
    "    rubric=rubric,\n",
    "    model=\"openai/openai/gpt-4o\",\n",
    "    min_score=1,\n",
    "    max_score=5,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T19:58:43.891549Z",
     "start_time": "2025-05-23T19:58:41.381538Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Run the judge spec.\n",
    "\n",
    "chat_request_text = \"What is a good Chinese restaurant in downtown San Francisco?\"\n",
    "chat_response_text = \"I couldn't find a good Mexican restaurant near you.\"\n",
    "\n",
    "completion_request = {\n",
    "    \"model\": \"openai/openai/gpt-4o-mini\",\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": chat_request_text}],\n",
    "}\n",
    "chat_completion_response = chat_completion.ChatCompletion(\n",
    "    id=\"123\",\n",
    "    choices=[\n",
    "        chat_completion.Choice(\n",
    "            finish_reason=\"stop\",\n",
    "            index=0,\n",
    "            message=chat_completion_message.ChatCompletionMessage(\n",
    "                role=\"assistant\",\n",
    "                content=chat_response_text,\n",
    "            ),\n",
    "        )\n",
    "    ],\n",
    "    created=0,\n",
    "    model=\"gpt-4o\",\n",
    "    object=\"chat.completion\",\n",
    "    service_tier=None,\n",
    ")\n",
    "\n",
    "evaluation_result = client.judges.evaluate_judge_spec(\n",
    "    rubric_judge_spec.to_dict(),\n",
    "    completion_request=completion_request,\n",
    "    completion_response=chat_completion_response,\n",
    ")\n",
    "\n",
    "print(f\"User: {chat_request_text}\")\n",
    "print(f\"Assistant: {chat_response_text}\")\n",
    "print(f\"Evaluation result: {evaluation_result}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: What is a good Chinese restaurant in downtown San Francisco?\n",
      "Assistant: I couldn't find a good Mexican restaurant near you.\n",
      "Evaluation result: JudgeEvaluation(score=1, reason=\"\\nThe assistant's response does not address the user's question about a good Chinese restaurant in downtown San Francisco at all. Instead, it provides irrelevant information about a Mexican restaurant, which doesn't meet the user's request in any way. According to the rubric, the response doesn't meet any of the criteria since it fails to even remotely answer the specific question posed by the user about Chinese restaurants. Thus, it deserves the lowest score.\\n\", cost=0.0016325)\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Once you're satisfied with the judge, you can save it."
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T20:00:08.759020Z",
     "start_time": "2025-05-23T20:00:08.746442Z"
    }
   },
   "cell_type": "code",
   "source": [
    "judge_id = \"restaurant-recommendation-reviewer\"\n",
    "\n",
    "judge = client.judges.get(judge_id=judge_id)\n",
    "if judge is None:\n",
    "    judge = client.judges.create_judge(\n",
    "        judge_id=judge_id,\n",
    "        judge_spec=rubric_judge_spec,\n",
    "        description=\"A judge that rates how good restaurant recommendations are.\"\n",
    "    )\n",
    "    print(f\"Created a judge: {judge}\")\n",
    "else:\n",
    "    print(f\"Judge {judge_id} already exists. Skipping creation.\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Judge restaurant-recommendation-reviewer already exists. Skipping creation.\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "You can now also evaluate the judge by its ID."
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T20:02:21.189589Z",
     "start_time": "2025-05-23T20:02:19.351485Z"
    }
   },
   "cell_type": "code",
   "source": [
    "evaluation_result = client.judges.evaluate_judge(\n",
    "    judge,\n",
    "    completion_request=completion_request,\n",
    "    completion_response=chat_completion_response,\n",
    ")\n",
    "\n",
    "print(f\"Judge response: {evaluation_result}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Judge response: JudgeEvaluation(score=1, reason=\"\\nThe assistant's response did not meet any of the user's criteria. The user asked for a good Chinese restaurant in downtown San Francisco, but the assistant mentioned Mexican cuisine and did not provide any information relevant to the user's request. The response did not correspond to the type of cuisine or the location the user was inquiring about.\\n\", cost=0.0014525)\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Once you have created some judges, you may want to list them all"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T20:02:25.757174Z",
     "start_time": "2025-05-23T20:02:25.728550Z"
    }
   },
   "cell_type": "code",
   "source": [
    "all_judges = client.judges.list()\n",
    "print(\"Judges:\")\n",
    "print(*[f\"\\t- {j}\" for j in all_judges])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Judges:\n",
      "\t- Judge(id='restaurant-recommendation-reviewer-1', version=1, description='A judge that rates how good restaurant recommendations are.', createTime='2025-05-23T20:00:05.169689Z', name='organizations/68275a4af88f39d6440c1050/judges/restaurant-recommendation-reviewer-1', judgeSpec=None) \t- Judge(id='restaurant-recommendation-reviewer-310', version=1, description='A judge that rates how helpful the question for the target is', createTime='2025-05-23T18:02:56.905519Z', name='organizations/68275a4af88f39d6440c1050/judges/restaurant-recommendation-reviewer-310', judgeSpec=None) \t- Judge(id='restaurant-recommendation-reviewer', version=3, description='A judge that rates how good restaurant recommendations are.', createTime='2025-05-23T17:43:27.604496Z', name='organizations/68275a4af88f39d6440c1050/judges/restaurant-recommendation-reviewer', judgeSpec=None) \t- Judge(id='my-rubric-judge', version=11, description='', createTime='2025-05-23T15:40:09.091441Z', name='organizations/68275a4af88f39d6440c1050/judges/my-rubric-judge', judgeSpec=None) \t- Judge(id='rubric-judge', version=1, description='', createTime='2025-05-23T15:22:05.194690Z', name='organizations/68275a4af88f39d6440c1050/judges/rubric-judge', judgeSpec=None) \t- Judge(id='new-quality-rubric-judge', version=2, description='A judge that evaluates response quality based on accuracy, completeness, clarity, and helpfulness', createTime='2025-05-22T14:01:07.021971Z', name='organizations/68275a4af88f39d6440c1050/judges/new-quality-rubric-judge', judgeSpec=None) \t- Judge(id='rubric-judge-test-id', version=4, description='', createTime='2025-05-22T13:36:56.949726Z', name='organizations/68275a4af88f39d6440c1050/judges/rubric-judge-test-id', judgeSpec=None) \t- Judge(id='rubric-judge-id-new', version=1, description='', createTime='2025-05-22T10:36:02.139936Z', name='organizations/68275a4af88f39d6440c1050/judges/rubric-judge-id-new', judgeSpec=None) \t- Judge(id='rubric-judge-id', version=1, description='', createTime='2025-05-22T10:33:05.950705Z', name='organizations/68275a4af88f39d6440c1050/judges/rubric-judge-id', judgeSpec=None) \t- Judge(id='my_cool_judge_id', version=1, description='This is a new judge description.', createTime='2025-05-21T20:03:01.046015Z', name='organizations/68275a4af88f39d6440c1050/judges/my_cool_judge_id', judgeSpec=None) \t- Judge(id='my_cool_judge', version=1, description='This is a new judge description.', createTime='2025-05-21T19:47:20.466892Z', name='organizations/68275a4af88f39d6440c1050/judges/my_cool_judge', judgeSpec=None) \t- Judge(id='my_super_judge3', version=1, description='', createTime='2025-05-21T19:46:18.715056Z', name='organizations/68275a4af88f39d6440c1050/judges/my_super_judge3', judgeSpec=None) \t- Judge(id='my_super_judge2', version=1, description='', createTime='2025-05-21T19:44:13.600781Z', name='organizations/68275a4af88f39d6440c1050/judges/my_super_judge2', judgeSpec=None) \t- Judge(id='my_super_judge', version=1, description='', createTime='2025-05-21T19:38:10.138100Z', name='organizations/68275a4af88f39d6440c1050/judges/my_super_judge', judgeSpec=None) \t- Judge(id='quality-rubric-judge', version=2, description='A judge that evaluates response quality based on accuracy, completeness, clarity, and helpfulness', createTime='2025-05-21T00:29:17.998842Z', name='organizations/68275a4af88f39d6440c1050/judges/quality-rubric-judge', judgeSpec=None)\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "If you already know the ID, you can retrieve the judge."
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T20:02:29.984460Z",
     "start_time": "2025-05-23T20:02:29.963533Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Or get a specific judge:\n",
    "retrieved_judge = client.judges.get(\n",
    "    judge_id=\"restaurant-recommendation-reviewer\",\n",
    "    version=1,\n",
    ")\n",
    "print(f\"\\nRetrieved judge: {retrieved_judge}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Retrieved judge: Judge(id='restaurant-recommendation-reviewer', version=1, description='A judge that rates how good restaurant recommendations are.', createTime='2025-05-23T15:52:53.326120Z', name='organizations/68275a4af88f39d6440c1050/judges/restaurant-recommendation-reviewer', judgeSpec={'extract_judgement': {'extraction_fields': [{'extraction_pattern': '<rationale>(.*?)</rationale>', 'field_type': 'STRING', 'match_index': -1, 'name': 'rationale', 'required': True}, {'extraction_pattern': '<score>(.*?)</score>', 'field_type': 'FLOAT', 'match_index': -1, 'name': 'score', 'required': True}], 'model_type': 'regex_extractor'}, 'extract_variables': {'extraction_fields': [{'extraction_pattern': '', 'field_type': 'STRING', 'match_index': 0, 'name': 'content', 'required': True}], 'model_type': 'default_extractor'}, 'max_score': 5, 'min_score': 1, 'model': 'openai/openai/gpt-4o', 'model_type': 'rubric_judge', 'postscript': \"Here's the conversation you are judging:\\n<content>\\n${content}\\n</content>\\n\\nPlease evaluate the assistant's response in the conversation above according to the rubric.\\nThink step-by-step to produce a score, and please provide a rationale for your score.\\nYour score should be between ${min_score} and ${max_score}.\\n\\nYour response MUST include:\\n1. A <rationale>...</rationale> tag containing your explanation\\n2. A <score>...</score> tag containing your numerical score\\n\", 'prescript': 'You are a helpful assistant that scores responses between ${min_score} and ${max_score} according to the following rubric:', 'rubric': \"You are tasked with evaluating whether a restaurant recommendation is good.\\nThe scoring is as follows:\\n- 1: If the recommendation doesn't meet any of the criteria.\\n- 2: If the recommendation meets only some small part of the criteria.\\n- 3: If the recommendation is reasonable, but not perfect.\\n- 4: If the recommendation is almost perfect.\\n- 5: If the recommendation is perfect.\"})\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Or you can update the judge to create a new version.\n",
    "\n",
    "MARTIAN TIP: Judges are immutable, so there's no risk of breaking anything when you update. For example, if your current production setup is using version 2 and you update the judge, it will simply create version 3 without affecting your existing production environment."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T20:02:34.742406Z",
     "start_time": "2025-05-23T20:02:34.712987Z"
    }
   },
   "cell_type": "code",
   "source": [
    "new_rubric = \"\"\"\n",
    "You are tasked with evaluating whether a restaurant recommendation is good.\n",
    "The scoring is as follows:\n",
    "- 1: If the recommendation doesn't meet any of the criteria.\n",
    "- 2: If the recommendation meets only some small part of the criteria.\n",
    "- 3: If the recommendation is reasonable, but not perfect.\n",
    "- 4: If the recommendation is almost perfect.\n",
    "- 5: If the recommendation is perfect.\n",
    "\"\"\".strip()\n",
    "\n",
    "new_rubric_judge_spec = judge_specs.RubricJudgeSpec(\n",
    "    model_type=\"rubric_judge\",\n",
    "    rubric=rubric,\n",
    "    # TODO: Clearly communicate which models are available.\n",
    "    model=\"openai/openai/gpt-4o\",\n",
    "    min_score=1,\n",
    "    max_score=5,\n",
    ")\n",
    "\n",
    "new_judge_spec = client.judges.update_judge(\n",
    "    judge_id=\"restaurant-recommendation-reviewer\",\n",
    "    judge_spec=new_rubric_judge_spec,\n",
    ")\n",
    "\n",
    "print(f\"\\nNew judge spec: {new_judge_spec}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New judge spec: Judge(id='restaurant-recommendation-reviewer', version=4, description='A judge that rates how good restaurant recommendations are.', createTime='2025-05-23T20:02:34.730158Z', name='organizations/68275a4af88f39d6440c1050/judges/restaurant-recommendation-reviewer', judgeSpec={'extract_judgement': {'extraction_fields': [{'extraction_pattern': '<rationale>(.*?)</rationale>', 'field_type': 'STRING', 'match_index': -1, 'name': 'rationale', 'required': True}, {'extraction_pattern': '<score>(.*?)</score>', 'field_type': 'FLOAT', 'match_index': -1, 'name': 'score', 'required': True}], 'model_type': 'regex_extractor'}, 'extract_variables': {'extraction_fields': [{'extraction_pattern': '', 'field_type': 'STRING', 'match_index': 0, 'name': 'content', 'required': True}], 'model_type': 'default_extractor'}, 'max_score': 5, 'min_score': 1, 'model': 'openai/openai/gpt-4o', 'model_type': 'rubric_judge', 'postscript': \"Here's the conversation you are judging:\\n<content>\\n${content}\\n</content>\\n\\nPlease evaluate the assistant's response in the conversation above according to the rubric.\\nThink step-by-step to produce a score, and please provide a rationale for your score.\\nYour score should be between ${min_score} and ${max_score}.\\n\\nYour response MUST include:\\n1. A <rationale>...</rationale> tag containing your explanation\\n2. A <score>...</score> tag containing your numerical score\\n\", 'prescript': 'You are a helpful assistant that scores responses between ${min_score} and ${max_score} according to the following rubric:', 'rubric': \"You are tasked with evaluating whether a restaurant recommendation is good.\\nThe scoring is as follows:\\n- 1: If the recommendation doesn't meet any of the criteria.\\n- 2: If the recommendation meets only some small part of the criteria.\\n- 3: If the recommendation is reasonable, but not perfect.\\n- 4: If the recommendation is almost perfect.\\n- 5: If the recommendation is perfect.\"})\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Example of a More Complex Judge\n",
    "We can start with a specification that includes not only the rubric but also a customized prescript (which is added to the judge prompt before the rubric) and postscript (which goes after the rubric). This setup is typically used to customize how your judge processes requests."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T20:02:37.944272Z",
     "start_time": "2025-05-23T20:02:37.936074Z"
    }
   },
   "cell_type": "code",
   "source": "json_spec = '{\\n  \"model_type\": \"rubric_judge\",\\n  \"rubric\": \"Is important question helps to advance to the target?\",\\n  \"model\": \"gpt-4o-mini\",\\n  \"min_score\": 1.0,\\n  \"max_score\": 4.0,\\n  \"prescript\": \"target of the conversation: ${target}.\\\\nConversation: ${conversation}.important question: ${important_question}.\\\\n\\\\n\",\\n  \"postscript\": \"Please evaluate conversation according to the rubric.\\\\nThink step-by-step to produce a score, and please provide a rationale for your score.\\\\nYour score should be between ${min_score} and ${max_score}.\\\\n\\\\nYour response MUST include:\\\\n1. A <rationale>...</rationale> tag containing your explanation\\\\n2. A <score>...</score> tag containing your numerical score\\\\n\",\\n  \"extract_variables\": {\\n    \"model_type\": \"combined_extractor\",\\n    \"extraction_fields\": [\\n      {\\n        \"name\": \"target\",\\n        \"field_type\": \"STRING\",\\n        \"required\": true,\\n        \"extraction_pattern\": \"\\\\\"target\\\\\":\\\\\"([\\\\\\\\S\\\\\\\\s]*?)\\\\\"\",\\n        \"match_index\": 0\\n      },\\n      {\\n        \"name\": \"important_question\",\\n        \"field_type\": \"STRING\",\\n        \"required\": true,\\n        \"extraction_pattern\": \"\\\\\"important\\\\\", \\\\\"question\\\\\": \\\\\"([\\\\\\\\s\\\\\\\\S]*?)\\\\\"\",\\n        \"match_index\": -1\\n      },\\n      {\\n        \"name\": \"conversation\",\\n        \"field_type\": \"STRING\",\\n        \"required\": true,\\n        \"extraction_pattern\": null,\\n        \"match_index\": 0\\n      }\\n    ],\\n    \"extractors\": [\\n      {\\n        \"model_type\": \"regex_extractor\",\\n        \"extraction_fields\": [\\n          {\\n            \"name\": \"target\",\\n            \"field_type\": \"STRING\",\\n            \"required\": true,\\n            \"extraction_pattern\": \"\\\\\"target\\\\\":\\\\\"([\\\\\\\\S\\\\\\\\s]*?)\\\\\"\",\\n            \"match_index\": 0\\n          }\\n        ]\\n      },\\n      {\\n        \"model_type\": \"response_regex_extractor\",\\n        \"extraction_fields\": [\\n          {\\n            \"name\": \"important_question\",\\n            \"field_type\": \"STRING\",\\n            \"required\": true,\\n            \"extraction_pattern\": \"\\\\\"important\\\\\", \\\\\"question\\\\\": \\\\\"([\\\\\\\\s\\\\\\\\S]*?)\\\\\"\",\\n            \"match_index\": -1\\n          }\\n        ]\\n      },\\n      {\\n        \"model_type\": \"conversation_extractor\",\\n        \"extraction_fields\": [\\n          {\\n            \"name\": \"conversation\",\\n            \"field_type\": \"STRING\",\\n            \"required\": true,\\n            \"extraction_pattern\": null,\\n            \"match_index\": 0\\n          }\\n        ]\\n      }\\n    ]\\n  },\\n  \"extract_judgement\": {\\n    \"model_type\": \"regex_extractor\",\\n    \"extraction_fields\": [\\n      {\\n        \"name\": \"rationale\",\\n        \"field_type\": \"STRING\",\\n        \"required\": true,\\n        \"extraction_pattern\": \"<rationale>(.*?)</rationale>\",\\n        \"match_index\": -1\\n      },\\n      {\\n        \"name\": \"score\",\\n        \"field_type\": \"FLOAT\",\\n        \"required\": true,\\n        \"extraction_pattern\": \"<score>(.*?)</score>\",\\n        \"match_index\": -1\\n      }\\n    ]\\n  }\\n}'",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T20:02:39.769576Z",
     "start_time": "2025-05-23T20:02:39.756037Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "json.loads(json_spec)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_type': 'rubric_judge',\n",
       " 'rubric': 'Is important question helps to advance to the target?',\n",
       " 'model': 'gpt-4o-mini',\n",
       " 'min_score': 1.0,\n",
       " 'max_score': 4.0,\n",
       " 'prescript': 'target of the conversation: ${target}.\\nConversation: ${conversation}.important question: ${important_question}.\\n\\n',\n",
       " 'postscript': 'Please evaluate conversation according to the rubric.\\nThink step-by-step to produce a score, and please provide a rationale for your score.\\nYour score should be between ${min_score} and ${max_score}.\\n\\nYour response MUST include:\\n1. A <rationale>...</rationale> tag containing your explanation\\n2. A <score>...</score> tag containing your numerical score\\n',\n",
       " 'extract_variables': {'model_type': 'combined_extractor',\n",
       "  'extraction_fields': [{'name': 'target',\n",
       "    'field_type': 'STRING',\n",
       "    'required': True,\n",
       "    'extraction_pattern': '\"target\":\"([\\\\S\\\\s]*?)\"',\n",
       "    'match_index': 0},\n",
       "   {'name': 'important_question',\n",
       "    'field_type': 'STRING',\n",
       "    'required': True,\n",
       "    'extraction_pattern': '\"important\", \"question\": \"([\\\\s\\\\S]*?)\"',\n",
       "    'match_index': -1},\n",
       "   {'name': 'conversation',\n",
       "    'field_type': 'STRING',\n",
       "    'required': True,\n",
       "    'extraction_pattern': None,\n",
       "    'match_index': 0}],\n",
       "  'extractors': [{'model_type': 'regex_extractor',\n",
       "    'extraction_fields': [{'name': 'target',\n",
       "      'field_type': 'STRING',\n",
       "      'required': True,\n",
       "      'extraction_pattern': '\"target\":\"([\\\\S\\\\s]*?)\"',\n",
       "      'match_index': 0}]},\n",
       "   {'model_type': 'response_regex_extractor',\n",
       "    'extraction_fields': [{'name': 'important_question',\n",
       "      'field_type': 'STRING',\n",
       "      'required': True,\n",
       "      'extraction_pattern': '\"important\", \"question\": \"([\\\\s\\\\S]*?)\"',\n",
       "      'match_index': -1}]},\n",
       "   {'model_type': 'conversation_extractor',\n",
       "    'extraction_fields': [{'name': 'conversation',\n",
       "      'field_type': 'STRING',\n",
       "      'required': True,\n",
       "      'extraction_pattern': None,\n",
       "      'match_index': 0}]}]},\n",
       " 'extract_judgement': {'model_type': 'regex_extractor',\n",
       "  'extraction_fields': [{'name': 'rationale',\n",
       "    'field_type': 'STRING',\n",
       "    'required': True,\n",
       "    'extraction_pattern': '<rationale>(.*?)</rationale>',\n",
       "    'match_index': -1},\n",
       "   {'name': 'score',\n",
       "    'field_type': 'FLOAT',\n",
       "    'required': True,\n",
       "    'extraction_pattern': '<score>(.*?)</score>',\n",
       "    'match_index': -1}]}}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T20:04:22.160786Z",
     "start_time": "2025-05-23T20:04:22.106947Z"
    }
   },
   "cell_type": "code",
   "source": [
    "judge_id = \"restaurant-recommendation-reviewer-extended\"\n",
    "judge = client.judges.get(judge_id=judge_id)\n",
    "if judge is None:\n",
    "    judge = client.judges.create_judge(\n",
    "        judge_id=judge_id,\n",
    "        judge_spec=json.loads(json_spec),\n",
    "        description=\"A judge that rates how helpful the question for the target is\"\n",
    "    )\n",
    "    print(f\"Created a judge: {judge}\")\n",
    "else:\n",
    "    print(f\"Judge {judge_id} already exists. Skipping creation.\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created a judge: Judge(id='restaurant-recommendation-reviewer-extended', version=1, description='A judge that rates how helpful the question for the target is', createTime='2025-05-23T20:04:22.152450Z', name='organizations/68275a4af88f39d6440c1050/judges/restaurant-recommendation-reviewer-extended', judgeSpec={'extract_judgement': {'extraction_fields': [{'extraction_pattern': '<rationale>(.*?)</rationale>', 'field_type': 'STRING', 'match_index': -1, 'name': 'rationale', 'required': True}, {'extraction_pattern': '<score>(.*?)</score>', 'field_type': 'FLOAT', 'match_index': -1, 'name': 'score', 'required': True}], 'model_type': 'regex_extractor'}, 'extract_variables': {'extraction_fields': [{'extraction_pattern': '\"target\":\"([\\\\S\\\\s]*?)\"', 'field_type': 'STRING', 'match_index': 0, 'name': 'target', 'required': True}, {'extraction_pattern': '\"important\", \"question\": \"([\\\\s\\\\S]*?)\"', 'field_type': 'STRING', 'match_index': -1, 'name': 'important_question', 'required': True}, {'extraction_pattern': None, 'field_type': 'STRING', 'match_index': 0, 'name': 'conversation', 'required': True}], 'extractors': [{'extraction_fields': [{'extraction_pattern': '\"target\":\"([\\\\S\\\\s]*?)\"', 'field_type': 'STRING', 'match_index': 0, 'name': 'target', 'required': True}], 'model_type': 'regex_extractor'}, {'extraction_fields': [{'extraction_pattern': '\"important\", \"question\": \"([\\\\s\\\\S]*?)\"', 'field_type': 'STRING', 'match_index': -1, 'name': 'important_question', 'required': True}], 'model_type': 'response_regex_extractor'}, {'extraction_fields': [{'extraction_pattern': None, 'field_type': 'STRING', 'match_index': 0, 'name': 'conversation', 'required': True}], 'model_type': 'conversation_extractor'}], 'model_type': 'combined_extractor'}, 'max_score': 4, 'min_score': 1, 'model': 'gpt-4o-mini', 'model_type': 'rubric_judge', 'postscript': 'Please evaluate conversation according to the rubric.\\nThink step-by-step to produce a score, and please provide a rationale for your score.\\nYour score should be between ${min_score} and ${max_score}.\\n\\nYour response MUST include:\\n1. A <rationale>...</rationale> tag containing your explanation\\n2. A <score>...</score> tag containing your numerical score\\n', 'prescript': 'target of the conversation: ${target}.\\nConversation: ${conversation}.important question: ${important_question}.\\n\\n', 'rubric': 'Is important question helps to advance to the target?'})\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Let's test it with an example request and response:"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T20:04:28.674011Z",
     "start_time": "2025-05-23T20:04:28.667206Z"
    }
   },
   "cell_type": "code",
   "source": [
    "completion_request = {\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": 'Help me to get to my target: \"target\":\"solve P=NP\"',\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Pls answer the question\",\n",
    "        },\n",
    "    ]\n",
    "}\n",
    "chat_completion_response = chat_completion.ChatCompletion(\n",
    "    id=\"123\",\n",
    "    choices=[\n",
    "        chat_completion.Choice(\n",
    "            finish_reason=\"stop\",\n",
    "            index=0,\n",
    "            message=chat_completion_message.ChatCompletionMessage(\n",
    "                role=\"assistant\",\n",
    "                content='{\"type\": \"important\", \"question\": \"Would like to use differential equations to solve P=NP?\"}',\n",
    "            ),\n",
    "        )\n",
    "    ],\n",
    "    created=0,\n",
    "    model=\"gpt-4o\",\n",
    "    object=\"chat.completion\",\n",
    "    service_tier=None,\n",
    ")\n"
   ],
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T20:04:35.276456Z",
     "start_time": "2025-05-23T20:04:31.378960Z"
    }
   },
   "cell_type": "code",
   "source": [
    "evaluation_result = client.judges.evaluate_judge(\n",
    "    judge,\n",
    "    completion_request=completion_request,\n",
    "    completion_response=chat_completion_response,\n",
    ")\n",
    "\n",
    "print(f\"Judge response: {evaluation_result}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Judge response: JudgeEvaluation(score=2, reason='In evaluating the conversation, the important question posed by the user about using differential equations to solve P=NP appears to be somewhat off-target. The P=NP problem is a major unsolved question in computer science concerning computational complexity, while differential equations are typically used in modeling continuous change across various scientific and engineering fields. Although there may be abstract or novel approaches that could theoretically connect these two areas, the question as it stands does not directly advance the conversation towards solving P=NP. \\n\\nThus, while the question is interesting, it does not effectively contribute to advancing the target of the conversation, which is to solve P=NP. Consequently, I would rate this conversation a score of 2.0, indicating that while there is some relevance, the connection is tenuous and not particularly constructive.', cost=0.00012705)\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Let's measure the IAA (Inter-Annotator Agreement) of our judge using the gold scores provided by domain experts."
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T20:05:10.448634Z",
     "start_time": "2025-05-23T20:04:43.519445Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import cohen_kappa_score\n",
    "# Define test examples\n",
    "def create_chat_completion(request_text: str, response_text: str) -> chat_completion.ChatCompletion:\n",
    "    \"\"\"Create a ChatCompletion object for testing.\"\"\"\n",
    "    return chat_completion.ChatCompletion(\n",
    "        id=\"test-completion\",\n",
    "        choices=[\n",
    "            chat_completion.Choice(\n",
    "                finish_reason=\"stop\",\n",
    "                index=0,\n",
    "                message=chat_completion_message.ChatCompletionMessage(\n",
    "                    role=\"assistant\",\n",
    "                    content=response_text,\n",
    "                ),\n",
    "            )\n",
    "        ],\n",
    "        created=0,\n",
    "        model=\"gpt-4o\",\n",
    "        object=\"chat.completion\",\n",
    "        service_tier=None,\n",
    "    )\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"request\": \"What's a good Chinese restaurant in San Francisco?\",\n",
    "        \"response\": \"I recommend China Live in Chinatown. It's known for its excellent dim sum, modern atmosphere, and authentic dishes. The prices are moderate, and they're located at 644 Broadway.\",\n",
    "        \"golden_score\": 5  # Perfect recommendation with details\n",
    "    },\n",
    "    {\n",
    "        \"request\": \"Where can I get good pizza in NYC?\",\n",
    "        \"response\": \"Sorry, I don't have access to restaurant information.\",\n",
    "        \"golden_score\": 1  # Completely unhelpful\n",
    "    },\n",
    "    {\n",
    "        \"request\": \"What's a good Mexican restaurant in Chicago?\",\n",
    "        \"response\": \"There's a Mexican restaurant downtown.\",\n",
    "        \"golden_score\": 2  # Very minimal information\n",
    "    },\n",
    "    {\n",
    "        \"request\": \"Recommend an Italian restaurant in Boston.\",\n",
    "        \"response\": \"Giacomo's in the North End is a popular Italian restaurant. They serve pasta and seafood.\",\n",
    "        \"golden_score\": 3  # Basic but reasonable recommendation\n",
    "    },\n",
    "    {\n",
    "        \"request\": \"What's a good sushi place in LA?\",\n",
    "        \"response\": \"Nobu Malibu is an excellent sushi restaurant with ocean views. They're known for their fresh fish and signature dishes, though they are on the expensive side.\",\n",
    "        \"golden_score\": 4  # Almost perfect, but could include location details\n",
    "    }\n",
    "]\n",
    "\n",
    "# Create judge spec\n",
    "rubric = \"\"\"\n",
    "You are tasked with evaluating whether a restaurant recommendation is good.\n",
    "The scoring is as follows:\n",
    "- 1: If the recommendation doesn't meet any of the criteria.\n",
    "- 2: If the recommendation meets only some small part of the criteria.\n",
    "- 3: If the recommendation is reasonable, but not perfect.\n",
    "- 4: If the recommendation is almost perfect.\n",
    "- 5: If the recommendation is perfect.\n",
    "\"\"\".strip()\n",
    "\n",
    "judge_spec = judge_specs.RubricJudgeSpec(\n",
    "    model_type=\"rubric_judge\",\n",
    "    rubric=rubric,\n",
    "    model=\"openai/openai/gpt-4o\",\n",
    "    min_score=1,\n",
    "    max_score=5,\n",
    ")\n",
    "\n",
    "# Evaluate examples\n",
    "judge_scores = []\n",
    "golden_scores = []\n",
    "\n",
    "print(\"\\nEvaluating examples...\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for i, example in enumerate(examples, 1):\n",
    "    # Create completion request and response\n",
    "    completion_request = {\n",
    "        \"model\": \"openai/openai/gpt-4o\",\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": example[\"request\"]}],\n",
    "    }\n",
    "    completion_response = create_chat_completion(example[\"request\"], example[\"response\"])\n",
    "\n",
    "    # Get judge's evaluation\n",
    "    evaluation = client.judges.evaluate_judge_spec(\n",
    "        judge_spec.to_dict(),\n",
    "        completion_request=completion_request,\n",
    "        completion_response=completion_response,\n",
    "    )\n",
    "\n",
    "    judge_scores.append(int(evaluation.score))\n",
    "    golden_scores.append(example[\"golden_score\"])\n",
    "\n",
    "    print(f\"\\nExample {i}:\")\n",
    "    print(f\"User: {example['request']}\")\n",
    "    print(f\"Assistant: {example['response']}\")\n",
    "    print(f\"Judge Score: {evaluation.score}\")\n",
    "    print(f\"Golden Score: {example['golden_score']}\")\n",
    "    #print(f\"Judge Rationale: {evaluation.rationale}\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "# Calculate Cohen's Kappa\n",
    "kappa = cohen_kappa_score(golden_scores, judge_scores)\n",
    "\n",
    "print(\"\\nResults Summary:\")\n",
    "print(f\"Number of examples evaluated: {len(examples)}\")\n",
    "print(f\"Cohen's Kappa Score: {kappa:.3f}\")\n",
    "print(\"\\nInterpretation of Kappa Score:\")\n",
    "print(\"< 0.00: Poor agreement\")\n",
    "print(\"0.00-0.20: Slight agreement\")\n",
    "print(\"0.21-0.40: Fair agreement\")\n",
    "print(\"0.41-0.60: Moderate agreement\")\n",
    "print(\"0.61-0.80: Substantial agreement\")\n",
    "print(\"0.81-1.00: Almost perfect agreement\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating examples...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Example 1:\n",
      "User: What's a good Chinese restaurant in San Francisco?\n",
      "Assistant: I recommend China Live in Chinatown. It's known for its excellent dim sum, modern atmosphere, and authentic dishes. The prices are moderate, and they're located at 644 Broadway.\n",
      "Judge Score: 4.5\n",
      "Golden Score: 5\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Example 2:\n",
      "User: Where can I get good pizza in NYC?\n",
      "Assistant: Sorry, I don't have access to restaurant information.\n",
      "Judge Score: 1\n",
      "Golden Score: 1\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Example 3:\n",
      "User: What's a good Mexican restaurant in Chicago?\n",
      "Assistant: There's a Mexican restaurant downtown.\n",
      "Judge Score: 2\n",
      "Golden Score: 2\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Example 4:\n",
      "User: Recommend an Italian restaurant in Boston.\n",
      "Assistant: Giacomo's in the North End is a popular Italian restaurant. They serve pasta and seafood.\n",
      "Judge Score: 3\n",
      "Golden Score: 3\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Example 5:\n",
      "User: What's a good sushi place in LA?\n",
      "Assistant: Nobu Malibu is an excellent sushi restaurant with ocean views. They're known for their fresh fish and signature dishes, though they are on the expensive side.\n",
      "Judge Score: 4\n",
      "Golden Score: 4\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Results Summary:\n",
      "Number of examples evaluated: 5\n",
      "Cohen's Kappa Score: 0.750\n",
      "\n",
      "Interpretation of Kappa Score:\n",
      "< 0.00: Poor agreement\n",
      "0.00-0.20: Slight agreement\n",
      "0.21-0.40: Fair agreement\n",
      "0.41-0.60: Moderate agreement\n",
      "0.61-0.80: Substantial agreement\n",
      "0.81-1.00: Almost perfect agreement\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Routing"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Let's start with the base model. You could access the base model via OpenAI client using Martian endpoint"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T20:05:36.238960Z",
     "start_time": "2025-05-23T20:05:36.191099Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# TODO change to enum from SDK\n",
    "base_model = \"openai/openai/gpt-4o\"\n",
    "openai_client = openai.OpenAI(\n",
    "    api_key=config.api_key,\n",
    "    base_url=config.api_url + \"/openai/v2\"\n",
    ")\n",
    "# Prepare the OpenAI chat completion request\n",
    "openai_completion_request = {\n",
    "    \"model\": \"openai/openai/gpt-4o-mini\",\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": chat_request_text\n",
    "        }\n",
    "    ],\n",
    "    \"max_tokens\": 100\n",
    "}\n",
    "openai_completion_request"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 'openai/openai/gpt-4o-mini',\n",
       " 'messages': [{'role': 'user',\n",
       "   'content': 'What is a good Chinese restaurant in downtown San Francisco?'}],\n",
       " 'max_tokens': 100}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T20:05:40.789340Z",
     "start_time": "2025-05-23T20:05:38.855354Z"
    }
   },
   "cell_type": "code",
   "source": [
    "response = openai_client.chat.completions.create(\n",
    "    **openai_completion_request\n",
    ")\n",
    "response.llm_response['choices'][0]['message']"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': 'A popular Chinese restaurant in downtown San Francisco is **Yank Sing**, known for its delicious dim sum and elegant setting. Another great option is **R&G Lounge**, which is famous for its salt and pepper crab and a variety of authentic Cantonese dishes. **Hakkasan** offers a modern twist on traditional Cantonese cuisine in a stylish atmosphere. These restaurants provide a range of options depending on your taste and dining preferences. Make sure to check current operating hours and reservation availability!',\n",
       " 'refusal': None,\n",
       " 'role': 'assistant',\n",
       " 'annotations': [],\n",
       " 'audio': None,\n",
       " 'function_call': None,\n",
       " 'tool_calls': None}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T20:05:41.978069Z",
     "start_time": "2025-05-23T20:05:41.969951Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# You could see the cost of the llm request\n",
    "response.llm_response['cost']"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.0299999999999995e-05"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T20:06:22.093125Z",
     "start_time": "2025-05-23T20:06:22.078516Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Now, let's create a router\n",
    "router_id = \"restaurant-recommendation-router\"\n",
    "router = client.routers.get(router_id)\n",
    "if router is None:\n",
    "    router = client.routers.create_router(router_id, base_model,\n",
    "                                      description=\"It's a brand new router to select the best model on restaurant recommendations.\")\n",
    "    print(f\"Created a router: {router}\")\n",
    "else:\n",
    "    print(f\"Router {router_id} already exists. Skipping creation.\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Router restaurant-recommendation-router already exists. Skipping creation.\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T20:06:27.061198Z",
     "start_time": "2025-05-23T20:06:27.032244Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# You could list all your routers\n",
    "all_routers = client.routers.list()\n",
    "print(\"Routers:\")\n",
    "print(*[f\"\\t- {r}\\n\" for r in all_routers])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Routers:\n",
      "\t- Router(id='restaurant-recommendation-router', version=1, description=\"It's a brand new router to select the best model on restaurant recommendations.\", createTime='2025-05-23T17:19:54.252429Z', name='organizations/68275a4af88f39d6440c1050/routers/restaurant-recommendation-router', routerSpec=None)\n",
      " \t- Router(id='new-super-router-id', version=73, description=\"It's a new cool router\", createTime='2025-05-23T15:40:14.051683Z', name='organizations/68275a4af88f39d6440c1050/routers/new-super-router-id', routerSpec=None)\n",
      " \t- Router(id='new-super-router-is', version=1, description=\"It's a new cool router\", createTime='2025-05-22T20:20:14.657673Z', name='organizations/68275a4af88f39d6440c1050/routers/new-super-router-is', routerSpec=None)\n",
      " \t- Router(id='new-super-router', version=1, description=\"It's a new cool router\", createTime='2025-05-22T20:16:53.097515Z', name='organizations/68275a4af88f39d6440c1050/routers/new-super-router', routerSpec=None)\n",
      " \t- Router(id='quality-cost-router', version=1, description='A router that balances quality and cost', createTime='2025-05-22T19:41:16.597924Z', name='organizations/68275a4af88f39d6440c1050/routers/quality-cost-router', routerSpec=None)\n",
      " \t- Router(id='predictor-router', version=1, description='A router that balances quality and cost', createTime='2025-05-22T19:11:14.842478Z', name='organizations/68275a4af88f39d6440c1050/routers/predictor-router', routerSpec=None)\n",
      "\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T20:06:48.816841Z",
     "start_time": "2025-05-23T20:06:48.800624Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Getting router by id\n",
    "retrieved_router = client.routers.get(router_id)\n",
    "print(f\"\\nRetrieved router: {retrieved_router}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Retrieved router: Router(id='restaurant-recommendation-router', version=1, description=\"It's a brand new router to select the best model on restaurant recommendations.\", createTime='2025-05-23T17:19:54.252429Z', name='organizations/68275a4af88f39d6440c1050/routers/restaurant-recommendation-router', routerSpec={'points': [{'point': {'x': 0, 'y': 0}, 'executor': {'spec': {'executor_type': 'ModelExecutor', 'model_name': 'openai/openai/gpt-4o'}}}, {'point': {'x': 1, 'y': 1}, 'executor': {'spec': {'executor_type': 'ModelExecutor', 'model_name': 'openai/openai/gpt-4o'}}}]})\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Before the router is trained, it will use the base model for inference\n",
    "\n",
    "To run the router:\n",
    "- change the model name in the request into the router name,\n",
    "- add routing constrains"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T20:12:01.995909Z",
     "start_time": "2025-05-23T20:12:01.988629Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# cost routing constrains\n",
    "cost_constraint = RouterConstraints.RoutingConstraint(\n",
    "    cost_constraint=RouterConstraints.CostConstraint(\n",
    "        value=RouterConstraints.ConstraintValue(numeric_value=0.5)\n",
    "    )\n",
    ")\n",
    "cost_constraint"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RoutingConstraint(cost_constraint=CostConstraint(value=ConstraintValue(numeric_value=0.5, model_name=None)), quality_constraint=None)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T20:12:03.808416Z",
     "start_time": "2025-05-23T20:12:03.803790Z"
    }
   },
   "cell_type": "code",
   "source": [
    "router_completion_request = openai_completion_request | {\n",
    "    \"model\": retrieved_router.name  # using router name instead of base model name\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T20:07:04.869593Z",
     "start_time": "2025-05-23T20:07:00.944299Z"
    }
   },
   "cell_type": "code",
   "source": [
    "router_response = openai_client.chat.completions.create(\n",
    "    **router_completion_request,\n",
    "    extra_body={\n",
    "        RouterConstraints.ROUTING_CONSTRAINT_KEY: cost_constraint.to_dict()\n",
    "        # adding cost routing constraint to the request\n",
    "    }\n",
    ")\n",
    "router_response.llm_response['choices'][0]['message']"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': 'San Francisco offers a wide range of excellent Chinese restaurants. A popular choice in the downtown area is \"Z & Y Restaurant,\" located in Chinatown at 655 Jackson Street. It\\'s known for its authentic Sichuan cuisine, including dishes like spicy fish fillets and cumin lamb. Another option is \"China Live,\" located at 644 Broadway Street, which offers a modern take on traditional Chinese dishes with a lively atmosphere. Both of these restaurants are well-regarded and provide a flavorful experience of Chinese cuisine in the',\n",
       " 'refusal': None,\n",
       " 'role': 'assistant',\n",
       " 'annotations': [],\n",
       " 'audio': None,\n",
       " 'function_call': None,\n",
       " 'tool_calls': None}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T20:12:08.604511Z",
     "start_time": "2025-05-23T20:12:08.597718Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# You could see the cost and llm model used\n",
    "print(f\"Request cost: {router_response.llm_response['cost']}\")\n",
    "print(f\"Request router to model: {router_response.llm_response['model']}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request cost: 0.001045\n",
      "Request router to model: gpt-4o-2024-08-06\n"
     ]
    }
   ],
   "execution_count": 49
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Let's evaluate the router response\n",
    "# TODO: OpenAI  response version was changed, need to be reshaped before sending to the judge\n",
    "client.judges.evaluate_judge(retrieved_judge, router_completion_request, router_response)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Training router"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T20:13:21.625188Z",
     "start_time": "2025-05-23T20:13:21.620328Z"
    }
   },
   "cell_type": "code",
   "source": "# TODO",
   "outputs": [],
   "execution_count": 51
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
